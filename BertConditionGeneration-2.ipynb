{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ml/miniconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - ipywidgets\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    conda-4.10.1               |   py38h578d9bd_0         3.1 MB  conda-forge\n",
      "    ipywidgets-7.6.3           |     pyhd3deb0d_0         101 KB  conda-forge\n",
      "    jupyterlab_widgets-1.0.0   |     pyhd8ed1ab_1         130 KB  conda-forge\n",
      "    openssl-1.1.1k             |       h7f98852_0         2.1 MB  conda-forge\n",
      "    widgetsnbextension-3.5.1   |   py38h578d9bd_4         1.8 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.2 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  ipywidgets         conda-forge/noarch::ipywidgets-7.6.3-pyhd3deb0d_0\n",
      "  jupyterlab_widgets conda-forge/noarch::jupyterlab_widgets-1.0.0-pyhd8ed1ab_1\n",
      "  widgetsnbextension conda-forge/linux-64::widgetsnbextension-3.5.1-py38h578d9bd_4\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  conda                                4.9.2-py38h578d9bd_0 --> 4.10.1-py38h578d9bd_0\n",
      "  openssl                                 1.1.1j-h7f98852_0 --> 1.1.1k-h7f98852_0\n",
      "\n",
      "\n",
      "Proceed ([y]/n)? ^C\n",
      "\n",
      "CondaSystemExit: \n",
      "Operation aborted.  Exiting.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vb1ORRIm7eoY",
    "outputId": "27ac581c-5782-4ba9-b0be-4b854da4458f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-1.3.1-py3-none-any.whl (805 kB)\n",
      "\u001b[K     |████████████████████████████████| 805 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4 in /home/ml/.local/lib/python3.8/site-packages (from pytorch-lightning) (1.6.0)\n",
      "Collecting torchmetrics>=0.2.0\n",
      "  Downloading torchmetrics-0.3.2-py3-none-any.whl (274 kB)\n",
      "\u001b[K     |████████████████████████████████| 274 kB 8.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /home/ml/.local/lib/python3.8/site-packages (from pytorch-lightning) (4.56.2)\n",
      "Collecting pyDeprecate==0.3.0\n",
      "  Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from pytorch-lightning) (1.19.5)\n",
      "Collecting fsspec[http]>=2021.4.0\n",
      "  Downloading fsspec-2021.5.0-py3-none-any.whl (111 kB)\n",
      "\u001b[K     |████████████████████████████████| 111 kB 8.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /home/ml/miniconda3/lib/python3.8/site-packages (from pytorch-lightning) (20.9)\n",
      "Collecting tensorboard!=2.5.0,>=2.2.0\n",
      "  Using cached tensorboard-2.4.1-py3-none-any.whl (10.6 MB)\n",
      "Requirement already satisfied: future>=0.17.1 in /home/ml/.local/lib/python3.8/site-packages (from pytorch-lightning) (0.18.2)\n",
      "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /home/ml/miniconda3/lib/python3.8/site-packages (from pytorch-lightning) (5.4.1)\n",
      "Requirement already satisfied: requests in /home/ml/miniconda3/lib/python3.8/site-packages (from fsspec[http]>=2021.4.0->pytorch-lightning) (2.24.0)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.7.4.post0-cp38-cp38-manylinux2014_x86_64.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=0.4 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.11.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.8.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.35.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.32.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.14.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (50.3.1.post20201107)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.2)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.15.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.26.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ml/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ml/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.7.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ml/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (4.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ml/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ml/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (0.4.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests->fsspec[http]>=2021.4.0->pytorch-lightning) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch-lightning) (3.1.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.6.3-cp38-cp38-manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[K     |████████████████████████████████| 324 kB 10.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.1.0-cp38-cp38-manylinux2014_x86_64.whl (159 kB)\n",
      "\u001b[K     |████████████████████████████████| 159 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning) (20.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5 in /home/ml/miniconda3/lib/python3.8/site-packages (from aiohttp->fsspec[http]>=2021.4.0->pytorch-lightning) (3.7.4.3)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Downloading async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/ml/.local/lib/python3.8/site-packages (from packaging->pytorch-lightning) (2.4.7)\n",
      "Installing collected packages: multidict, yarl, async-timeout, fsspec, aiohttp, torchmetrics, tensorboard, pyDeprecate, pytorch-lightning\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.5.0\n",
      "    Uninstalling tensorboard-2.5.0:\n",
      "      Successfully uninstalled tensorboard-2.5.0\n",
      "Successfully installed aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.5.0 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.1 tensorboard-2.4.1 torchmetrics-0.3.2 yarl-1.6.3\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.1.1 is available.\n",
      "You should consider upgrading via the '/home/ml/miniconda3/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v_LINeGbz0Te"
   },
   "outputs": [],
   "source": [
    "from transformers import BertPreTrainedModel, BertModel\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HmTsH4Kp2sbf"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "i7A3DXqN2d39"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict, UserDict\n",
    "from typing import Tuple, Any, Optional\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "from dataclasses import fields\n",
    "\n",
    "\n",
    "\n",
    "class ModelOutput(OrderedDict):\n",
    "    \"\"\"\n",
    "    Base class for all model outputs as dataclass. Has a ``__getitem__`` that allows indexing by integer or slice (like\n",
    "    a tuple) or strings (like a dictionary) that will ignore the ``None`` attributes. Otherwise behaves like a regular\n",
    "    python dictionary.\n",
    "    .. warning::\n",
    "        You can't unpack a :obj:`ModelOutput` directly. Use the :meth:`~transformers.file_utils.ModelOutput.to_tuple`\n",
    "        method to convert it to a tuple before.\n",
    "    \"\"\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        class_fields = fields(self)\n",
    "\n",
    "        # Safety and consistency checks\n",
    "        assert len(class_fields), f\"{self.__class__.__name__} has no fields.\"\n",
    "        assert all(\n",
    "            field.default is None for field in class_fields[1:]\n",
    "        ), f\"{self.__class__.__name__} should not have more than one required field.\"\n",
    "\n",
    "        first_field = getattr(self, class_fields[0].name)\n",
    "        other_fields_are_none = all(getattr(self, field.name) is None for field in class_fields[1:])\n",
    "\n",
    "        if other_fields_are_none and not is_tensor(first_field):\n",
    "            try:\n",
    "                iterator = iter(first_field)\n",
    "                first_field_iterator = True\n",
    "            except TypeError:\n",
    "                first_field_iterator = False\n",
    "\n",
    "            # if we provided an iterator as first field and the iterator is a (key, value) iterator\n",
    "            # set the associated fields\n",
    "            if first_field_iterator:\n",
    "                for element in iterator:\n",
    "                    if (\n",
    "                        not isinstance(element, (list, tuple))\n",
    "                        or not len(element) == 2\n",
    "                        or not isinstance(element[0], str)\n",
    "                    ):\n",
    "                        break\n",
    "                    setattr(self, element[0], element[1])\n",
    "                    if element[1] is not None:\n",
    "                        self[element[0]] = element[1]\n",
    "            elif first_field is not None:\n",
    "                self[class_fields[0].name] = first_field\n",
    "        else:\n",
    "            for field in class_fields:\n",
    "                v = getattr(self, field.name)\n",
    "                if v is not None:\n",
    "                    self[field.name] = v\n",
    "\n",
    "    def __delitem__(self, *args, **kwargs):\n",
    "        raise Exception(f\"You cannot use ``__delitem__`` on a {self.__class__.__name__} instance.\")\n",
    "\n",
    "    def setdefault(self, *args, **kwargs):\n",
    "        raise Exception(f\"You cannot use ``setdefault`` on a {self.__class__.__name__} instance.\")\n",
    "\n",
    "    def pop(self, *args, **kwargs):\n",
    "        raise Exception(f\"You cannot use ``pop`` on a {self.__class__.__name__} instance.\")\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        raise Exception(f\"You cannot use ``update`` on a {self.__class__.__name__} instance.\")\n",
    "\n",
    "    def __getitem__(self, k):\n",
    "        if isinstance(k, str):\n",
    "            inner_dict = {k: v for (k, v) in self.items()}\n",
    "            return inner_dict[k]\n",
    "        else:\n",
    "            return self.to_tuple()[k]\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        if name in self.keys() and value is not None:\n",
    "            # Don't call self.__setitem__ to avoid recursion errors\n",
    "            super().__setitem__(name, value)\n",
    "        super().__setattr__(name, value)\n",
    "\n",
    "    def __setitem__(self, key, value):\n",
    "        # Will raise a KeyException if needed\n",
    "        super().__setitem__(key, value)\n",
    "        # Don't call self.__setattr__ to avoid recursion errors\n",
    "        super().__setattr__(key, value)\n",
    "\n",
    "    def to_tuple(self) -> Tuple[Any]:\n",
    "        \"\"\"\n",
    "        Convert self to a tuple containing all the attributes/keys that are not ``None``.\n",
    "        \"\"\"\n",
    "        return tuple(self[k] for k in self.keys())\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class MaskedLMOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    Base class for masked language models outputs.\n",
    "    Args:\n",
    "        loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`labels` is provided):\n",
    "            Masked language modeling (MLM) loss.\n",
    "        logits (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`):\n",
    "            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n",
    "        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_hidden_states=True`` is passed or when ``config.output_hidden_states=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n",
    "            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n",
    "            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n",
    "        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``output_attentions=True`` is passed or when ``config.output_attentions=True``):\n",
    "            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape :obj:`(batch_size, num_heads,\n",
    "            sequence_length, sequence_length)`.\n",
    "            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
    "            heads.\n",
    "    \"\"\"\n",
    "\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor]] = None\n",
    "\n",
    "\n",
    "class BertPredictionHeadTransform(nn.Module):\n",
    "    def __init__(self, hidden_size, sent_size, hidden_act, layer_norm_eps):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(hidden_size, hidden_size - sent_size)\n",
    "        if isinstance(hidden_act, str):\n",
    "            self.transform_act_fn = ACT2FN[hidden_act]\n",
    "        else:\n",
    "            self.transform_act_fn = hidden_act\n",
    "        self.LayerNorm = nn.LayerNorm(hidden_size - sent_size, eps=layer_norm_eps)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.transform_act_fn(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class BertLMPredictionHead(nn.Module):\n",
    "    def __init__(self, hidden_size, sent_size, hidden_act, layer_norm_eps, vocab_size):\n",
    "        super().__init__()\n",
    "        self.transform = BertPredictionHeadTransform(hidden_size, sent_size, hidden_act, layer_norm_eps)\n",
    "        # The output weights are the same as the input embeddings, but there is\n",
    "        # an output-only bias for each token.\n",
    "        self.decoder = nn.Linear(hidden_size - sent_size, vocab_size, bias=False)\n",
    "     \n",
    "        self.bias = nn.Parameter(torch.zeros(vocab_size))\n",
    "\n",
    "        # # Need a link between the two variables so that the bias is correctly resized with `resize_token_embeddings`\n",
    "        self.decoder.bias = self.bias\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = self.transform(hidden_states)\n",
    "        hidden_states = self.decoder(hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "class BertOnlyMLMHead_(nn.Module):\n",
    "    def __init__(self, hidden_size, sent_size, hidden_act, layer_norm_eps, vocab_size):\n",
    "        super().__init__()\n",
    "        self.predictions = BertLMPredictionHead(hidden_size, sent_size, hidden_act, layer_norm_eps, vocab_size)\n",
    "\n",
    "    def forward(self, sequence_output):\n",
    "        prediction_scores = self.predictions(sequence_output)\n",
    "        return prediction_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BxCGpNCl_IIF"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from packaging import version\n",
    "\n",
    "def _gelu_python(x):\n",
    "    \"\"\"\n",
    "    Original Implementation of the GELU activation function in Google BERT repo when initially created. For\n",
    "    information: OpenAI GPT's GELU is slightly different (and gives slightly different results): 0.5 * x * (1 +\n",
    "    torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3)))) This is now written in C in\n",
    "    torch.nn.functional Also see the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    return x * 0.5 * (1.0 + torch.erf(x / math.sqrt(2.0)))\n",
    "\n",
    "\n",
    "def gelu_new(x):\n",
    "    \"\"\"\n",
    "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT). Also see\n",
    "    the Gaussian Error Linear Units paper: https://arxiv.org/abs/1606.08415\n",
    "    \"\"\"\n",
    "    return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
    "\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.4\"):\n",
    "    gelu = _gelu_python\n",
    "else:\n",
    "    gelu = F.gelu\n",
    "\n",
    "\n",
    "def gelu_fast(x):\n",
    "    return 0.5 * x * (1.0 + torch.tanh(x * 0.7978845608 * (1.0 + 0.044715 * x * x)))\n",
    "\n",
    "\n",
    "def quick_gelu(x):\n",
    "    return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "\n",
    "def _silu_python(x):\n",
    "    \"\"\"\n",
    "    See Gaussian Error Linear Units (Hendrycks et al., https://arxiv.org/abs/1606.08415) where the SiLU (Sigmoid Linear\n",
    "    Unit) was originally introduced and coined, and see Sigmoid-Weighted Linear Units for Neural Network Function\n",
    "    Approximation in Reinforcement Learning (Elfwing et al., https://arxiv.org/abs/1702.03118) and Swish: a Self-Gated\n",
    "    Activation Function (Ramachandran et al., https://arxiv.org/abs/1710.05941v1) where the SiLU was experimented with\n",
    "    later.\n",
    "    \"\"\"\n",
    "    return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "if version.parse(torch.__version__) < version.parse(\"1.7\"):\n",
    "    silu = _silu_python\n",
    "else:\n",
    "    silu = F.silu\n",
    "\n",
    "\n",
    "def mish(x):\n",
    "    return x * torch.tanh(torch.nn.functional.softplus(x))\n",
    "\n",
    "\n",
    "def linear_act(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z8uad-9JPP0-"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "ACT2FN = {\n",
    "    \"relu\": F.relu,\n",
    "    \"silu\": silu,\n",
    "    \"swish\": silu,\n",
    "    \"gelu\": gelu,\n",
    "    \"tanh\": torch.tanh,\n",
    "    \"gelu_new\": gelu_new,\n",
    "    \"gelu_fast\": gelu_fast,\n",
    "    \"quick_gelu\": quick_gelu,\n",
    "    \"mish\": mish,\n",
    "    \"linear\": linear_act,\n",
    "    \"sigmoid\": torch.sigmoid,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LekH4H6x16aA",
    "outputId": "8332f7af-92e6-44a3-f108-9ffac3b35d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-18 01:39:42--  https://raw.githubusercontent.com/daria-sa/TST/main/YELP_with_sentiment_tags.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20211271 (19M) [text/plain]\n",
      "Saving to: ‘YELP_with_sentiment_tags.json’\n",
      "\n",
      "YELP_with_sentiment 100%[===================>]  19,27M  31,2MB/s    in 0,6s    \n",
      "\n",
      "2021-05-18 01:39:43 (31,2 MB/s) - ‘YELP_with_sentiment_tags.json’ saved [20211271/20211271]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/daria-sa/TST/main/YELP_with_sentiment_tags.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Txw3oP9019uF"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = json.load(open(\"YELP_with_sentiment_tags.json\"))\n",
    "data = eval(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "qIwngAVd3Tbt"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "\n",
    "class MLMDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "      self, \n",
    "      data: List[dict], \n",
    "      model_path_or_name: str = 'bert-base-cased',\n",
    "      pad_token: str = \"[PAD]\",\n",
    "      cls_token: str = \"[CLS]\",\n",
    "      sep_token: str = \"[SEP]\",\n",
    "      unk_token: str = \"[UNK]\",\n",
    "      mask_token: str = \"[MASK]\"\n",
    "      ):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_path_or_name, do_lower_case=False)\n",
    "        self.pad_token = pad_token\n",
    "        self.cls_token = cls_token\n",
    "        self.sep_token = sep_token\n",
    "        self.unk_token = unk_token\n",
    "        self.mask_token = mask_token\n",
    "        self.pad_idx = 0\n",
    "        self.max_sequence_length = 512\n",
    "        self.prep_samples = self.prepare_data(data)\n",
    "    \n",
    "    def prepare_data(self, data):\n",
    "        max_seq_length_without_special = 510\n",
    "        prep_samples = []\n",
    "\n",
    "        for input_sample in tqdm(data):\n",
    "            sample = {\"labels\": [], \"sentiment_labels\": [], \"input_ids\": []}\n",
    "            for orig_token, label in zip(input_sample[\"tokenized_text\"], input_sample[\"senti_tags\"]):\n",
    "                orig_token = str(orig_token)\n",
    "                label = int(label) + 2\n",
    "                cur_tokens = self.tokenizer.tokenize(str(orig_token))\n",
    "                if not cur_tokens:\n",
    "                    cur_tokens = [self.tokenizer.convert_tokens_to_ids(self.unk_token)]\n",
    "                if label != 2:\n",
    "                    for _ in cur_tokens:\n",
    "                        sample[\"input_ids\"].append(self.tokenizer.convert_tokens_to_ids(self.mask_token))\n",
    "                        sample[\"sentiment_labels\"].append(label)\n",
    "                    sample[\"labels\"].extend(cur_tokens)\n",
    "\n",
    "                else:\n",
    "                    sample[\"input_ids\"].extend(cur_tokens)\n",
    "                    sample[\"labels\"].extend(cur_tokens)\n",
    "                    sample[\"sentiment_labels\"].extend([label] * len(cur_tokens))\n",
    "\n",
    "\n",
    "            for k, v in sample.items():\n",
    "                sample[k] = v[:max_seq_length_without_special]\n",
    "\n",
    "            sample[\"input_ids\"] = self.tokenizer.convert_tokens_to_ids(\n",
    "                [self.cls_token] + sample[\"input_ids\"] + [self.sep_token]\n",
    "            )\n",
    "            sample[\"labels\"] = self.tokenizer.convert_tokens_to_ids(\n",
    "                [self.cls_token] + sample[\"labels\"] + [self.sep_token]\n",
    "            )\n",
    "            sample[\"input_mask\"] = [1] * len(sample[\"input_ids\"])\n",
    "            sample[\"sentiment_labels\"] = [2] + sample[\"sentiment_labels\"] + [2]\n",
    "\n",
    "\n",
    "            while len(sample[\"input_ids\"]) < self.max_sequence_length:\n",
    "                sample[\"input_ids\"].append(self.pad_idx)\n",
    "                sample[\"labels\"].append(self.pad_idx)\n",
    "                sample[\"input_mask\"].append(0)\n",
    "                sample[\"sentiment_labels\"].append(2)\n",
    "\n",
    "            sample[\"input_type_ids\"] = [0] * len(sample[\"input_ids\"])\n",
    "            prep_samples.append(sample)\n",
    "        return prep_samples\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.prep_samples[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.prep_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kC3PuchyJoQ8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class TextDataLoader(DataLoader):\n",
    "    def __init__(self, dataset, batch_size, shuffle, device):\n",
    "        super(TextDataLoader, self).__init__(\n",
    "            dataset, batch_size, collate_fn=self.collate_fn, shuffle=shuffle\n",
    "        )\n",
    "        self.device = device\n",
    "        self.tokens = []\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        input_ids_batch = []\n",
    "        input_mask_batch = []\n",
    "        input_type_ids_batch = []\n",
    "        labels_batch = []\n",
    "        sentiment_labels_batch = []\n",
    "        \n",
    "        max_len = max([sum(i[\"input_mask\"]) for i in data])\n",
    "\n",
    "        for sample in data:\n",
    "\n",
    "            input_ids_batch.append(sample[\"input_ids\"][:max_len])\n",
    "            input_mask_batch.append(sample[\"input_mask\"][:max_len])\n",
    "            input_type_ids_batch.append(sample[\"input_type_ids\"][:max_len])\n",
    "            labels_batch.append(sample[\"labels\"][:max_len])\n",
    "            sentiment_labels_batch.append(sample[\"sentiment_labels\"][:max_len])\n",
    "\n",
    "        batch = {\n",
    "            \"input_ids\": torch.tensor(\n",
    "                input_ids_batch, dtype=torch.int64, device=self.device),\n",
    "            \"attention_mask\": torch.tensor(\n",
    "                input_mask_batch, dtype=torch.int64, device=self.device),\n",
    "            \"token_type_ids\": torch.tensor(\n",
    "                input_type_ids_batch, dtype=torch.int64, device=self.device),\n",
    "            \"labels\": torch.tensor(\n",
    "                labels_batch, dtype=torch.int64, device=self.device),\n",
    "            \"sentiment_labels\": torch.tensor(\n",
    "                sentiment_labels_batch, dtype=torch.int64, device=self.device)\n",
    "            \n",
    "        }\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zK4NmOhsIwN6",
    "outputId": "c132b9f3-93eb-4f85-d628-513a50767e91",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 22/7000 [00:00<00:31, 218.59it/s]\u001b[A\n",
      "  1%|          | 50/7000 [00:00<00:30, 226.45it/s]\u001b[A\n",
      "  1%|          | 73/7000 [00:00<00:33, 204.92it/s]\u001b[A\n",
      "  1%|▏         | 94/7000 [00:00<00:35, 196.75it/s]\u001b[A\n",
      "  2%|▏         | 119/7000 [00:00<00:32, 213.70it/s]\u001b[A\n",
      "  2%|▏         | 145/7000 [00:00<00:30, 225.20it/s]\u001b[A\n",
      "  2%|▏         | 170/7000 [00:00<00:29, 232.60it/s]\u001b[A\n",
      "  3%|▎         | 197/7000 [00:00<00:28, 237.54it/s]\u001b[A\n",
      "  3%|▎         | 222/7000 [00:00<00:28, 240.71it/s]\u001b[A\n",
      "  4%|▎         | 247/7000 [00:01<00:29, 230.72it/s]\u001b[A\n",
      "  4%|▍         | 274/7000 [00:01<00:27, 241.40it/s]\u001b[A\n",
      "  4%|▍         | 299/7000 [00:01<00:30, 222.81it/s]\u001b[A\n",
      "  5%|▍         | 323/7000 [00:01<00:29, 226.64it/s]\u001b[A\n",
      "  5%|▍         | 346/7000 [00:01<00:30, 216.08it/s]\u001b[A\n",
      "  5%|▌         | 368/7000 [00:01<00:31, 213.33it/s]\u001b[A\n",
      "  6%|▌         | 394/7000 [00:01<00:29, 223.58it/s]\u001b[A\n",
      "  6%|▌         | 417/7000 [00:01<00:30, 217.94it/s]\u001b[A\n",
      "  6%|▋         | 439/7000 [00:01<00:31, 207.23it/s]\u001b[A\n",
      "  7%|▋         | 461/7000 [00:02<00:31, 208.87it/s]\u001b[A\n",
      "  7%|▋         | 482/7000 [00:02<00:31, 205.68it/s]\u001b[A\n",
      "  7%|▋         | 505/7000 [00:02<00:30, 211.99it/s]\u001b[A\n",
      "  8%|▊         | 527/7000 [00:02<00:31, 206.45it/s]\u001b[A\n",
      "  8%|▊         | 553/7000 [00:02<00:29, 221.00it/s]\u001b[A\n",
      "  8%|▊         | 576/7000 [00:02<00:30, 213.18it/s]\u001b[A\n",
      "  9%|▊         | 603/7000 [00:02<00:28, 228.26it/s]\u001b[A\n",
      "  9%|▉         | 627/7000 [00:02<00:28, 224.93it/s]\u001b[A\n",
      "  9%|▉         | 650/7000 [00:02<00:31, 203.90it/s]\u001b[A\n",
      " 10%|▉         | 671/7000 [00:03<00:31, 202.98it/s]\u001b[A\n",
      " 10%|▉         | 692/7000 [00:03<00:31, 200.89it/s]\u001b[A\n",
      " 10%|█         | 714/7000 [00:03<00:30, 205.80it/s]\u001b[A\n",
      " 10%|█         | 735/7000 [00:03<00:31, 201.73it/s]\u001b[A\n",
      " 11%|█         | 756/7000 [00:03<00:30, 201.52it/s]\u001b[A\n",
      " 11%|█         | 777/7000 [00:03<00:32, 190.81it/s]\u001b[A\n",
      " 11%|█▏        | 802/7000 [00:03<00:30, 206.25it/s]\u001b[A\n",
      " 12%|█▏        | 826/7000 [00:03<00:28, 213.77it/s]\u001b[A\n",
      " 12%|█▏        | 848/7000 [00:03<00:30, 201.40it/s]\u001b[A\n",
      " 12%|█▏        | 872/7000 [00:04<00:28, 211.34it/s]\u001b[A\n",
      " 13%|█▎        | 896/7000 [00:04<00:28, 216.36it/s]\u001b[A\n",
      " 13%|█▎        | 921/7000 [00:04<00:26, 225.22it/s]\u001b[A\n",
      " 13%|█▎        | 944/7000 [00:04<00:29, 208.73it/s]\u001b[A\n",
      " 14%|█▍        | 966/7000 [00:04<00:28, 210.20it/s]\u001b[A\n",
      " 14%|█▍        | 989/7000 [00:04<00:27, 215.07it/s]\u001b[A\n",
      " 15%|█▍        | 1016/7000 [00:04<00:26, 229.87it/s]\u001b[A\n",
      " 15%|█▍        | 1040/7000 [00:04<00:27, 218.91it/s]\u001b[A\n",
      " 15%|█▌        | 1063/7000 [00:04<00:28, 207.07it/s]\u001b[A\n",
      " 15%|█▌        | 1084/7000 [00:05<00:29, 201.89it/s]\u001b[A\n",
      " 16%|█▌        | 1108/7000 [00:05<00:28, 207.65it/s]\u001b[A\n",
      " 16%|█▌        | 1129/7000 [00:05<00:29, 202.23it/s]\u001b[A\n",
      " 16%|█▋        | 1155/7000 [00:05<00:26, 217.84it/s]\u001b[A\n",
      " 17%|█▋        | 1177/7000 [00:05<00:28, 204.89it/s]\u001b[A\n",
      " 17%|█▋        | 1199/7000 [00:05<00:28, 206.91it/s]\u001b[A\n",
      " 17%|█▋        | 1222/7000 [00:05<00:27, 212.54it/s]\u001b[A\n",
      " 18%|█▊        | 1244/7000 [00:05<00:27, 207.10it/s]\u001b[A\n",
      " 18%|█▊        | 1267/7000 [00:05<00:26, 213.43it/s]\u001b[A\n",
      " 18%|█▊        | 1295/7000 [00:06<00:24, 232.13it/s]\u001b[A\n",
      " 19%|█▉        | 1321/7000 [00:06<00:23, 239.17it/s]\u001b[A\n",
      " 19%|█▉        | 1346/7000 [00:06<00:24, 232.53it/s]\u001b[A\n",
      " 20%|█▉        | 1370/7000 [00:06<00:24, 226.68it/s]\u001b[A\n",
      " 20%|█▉        | 1393/7000 [00:06<00:24, 225.29it/s]\u001b[A\n",
      " 20%|██        | 1418/7000 [00:06<00:24, 229.58it/s]\u001b[A\n",
      " 21%|██        | 1442/7000 [00:06<00:24, 227.75it/s]\u001b[A\n",
      " 21%|██        | 1465/7000 [00:06<00:24, 226.28it/s]\u001b[A\n",
      " 21%|██▏       | 1489/7000 [00:06<00:24, 226.57it/s]\u001b[A\n",
      " 22%|██▏       | 1512/7000 [00:06<00:24, 226.73it/s]\u001b[A\n",
      " 22%|██▏       | 1535/7000 [00:07<00:24, 219.76it/s]\u001b[A\n",
      " 22%|██▏       | 1558/7000 [00:07<00:24, 218.67it/s]\u001b[A\n",
      " 23%|██▎       | 1584/7000 [00:07<00:23, 228.89it/s]\u001b[A\n",
      " 23%|██▎       | 1607/7000 [00:07<00:23, 228.46it/s]\u001b[A\n",
      " 23%|██▎       | 1633/7000 [00:07<00:22, 236.21it/s]\u001b[A\n",
      " 24%|██▎       | 1657/7000 [00:07<00:23, 226.56it/s]\u001b[A\n",
      " 24%|██▍       | 1680/7000 [00:07<00:23, 223.96it/s]\u001b[A\n",
      " 24%|██▍       | 1703/7000 [00:07<00:25, 209.07it/s]\u001b[A\n",
      " 25%|██▍       | 1727/7000 [00:07<00:24, 217.04it/s]\u001b[A\n",
      " 25%|██▌       | 1753/7000 [00:08<00:23, 225.86it/s]\u001b[A\n",
      " 25%|██▌       | 1776/7000 [00:08<00:24, 211.75it/s]\u001b[A\n",
      " 26%|██▌       | 1800/7000 [00:08<00:24, 215.89it/s]\u001b[A\n",
      " 26%|██▌       | 1822/7000 [00:08<00:24, 210.86it/s]\u001b[A\n",
      " 26%|██▋       | 1844/7000 [00:08<00:24, 207.71it/s]\u001b[A\n",
      " 27%|██▋       | 1869/7000 [00:08<00:23, 218.87it/s]\u001b[A\n",
      " 27%|██▋       | 1892/7000 [00:08<00:25, 201.39it/s]\u001b[A\n",
      " 27%|██▋       | 1913/7000 [00:08<00:26, 191.03it/s]\u001b[A\n",
      " 28%|██▊       | 1933/7000 [00:08<00:26, 187.95it/s]\u001b[A\n",
      " 28%|██▊       | 1956/7000 [00:09<00:25, 197.57it/s]\u001b[A\n",
      " 28%|██▊       | 1976/7000 [00:09<00:25, 194.22it/s]\u001b[A\n",
      " 29%|██▊       | 2000/7000 [00:09<00:24, 201.50it/s]\u001b[A\n",
      " 29%|██▉       | 2024/7000 [00:09<00:23, 209.52it/s]\u001b[A\n",
      " 29%|██▉       | 2047/7000 [00:09<00:23, 215.16it/s]\u001b[A\n",
      " 30%|██▉       | 2072/7000 [00:09<00:22, 223.87it/s]\u001b[A\n",
      " 30%|███       | 2103/7000 [00:09<00:19, 246.40it/s]\u001b[A\n",
      " 30%|███       | 2128/7000 [00:09<00:21, 223.98it/s]\u001b[A\n",
      " 31%|███       | 2151/7000 [00:09<00:23, 205.63it/s]\u001b[A\n",
      " 31%|███       | 2177/7000 [00:10<00:21, 219.89it/s]\u001b[A\n",
      " 31%|███▏      | 2200/7000 [00:10<00:23, 208.33it/s]\u001b[A\n",
      " 32%|███▏      | 2222/7000 [00:10<00:22, 208.46it/s]\u001b[A\n",
      " 32%|███▏      | 2253/7000 [00:10<00:20, 234.54it/s]\u001b[A\n",
      " 33%|███▎      | 2278/7000 [00:10<00:19, 236.57it/s]\u001b[A\n",
      " 33%|███▎      | 2307/7000 [00:10<00:19, 245.07it/s]\u001b[A\n",
      " 33%|███▎      | 2332/7000 [00:10<00:21, 219.45it/s]\u001b[A\n",
      " 34%|███▎      | 2355/7000 [00:10<00:21, 217.71it/s]\u001b[A\n",
      " 34%|███▍      | 2385/7000 [00:10<00:19, 238.79it/s]\u001b[A\n",
      " 34%|███▍      | 2410/7000 [00:11<00:19, 232.29it/s]\u001b[A\n",
      " 35%|███▍      | 2434/7000 [00:11<00:20, 221.44it/s]\u001b[A\n",
      " 35%|███▌      | 2461/7000 [00:11<00:19, 234.33it/s]\u001b[A\n",
      " 36%|███▌      | 2485/7000 [00:11<00:19, 227.63it/s]\u001b[A\n",
      " 36%|███▌      | 2509/7000 [00:11<00:20, 224.20it/s]\u001b[A\n",
      " 36%|███▌      | 2532/7000 [00:11<00:19, 225.62it/s]\u001b[A\n",
      " 37%|███▋      | 2557/7000 [00:11<00:19, 231.00it/s]\u001b[A\n",
      " 37%|███▋      | 2585/7000 [00:11<00:18, 242.88it/s]\u001b[A\n",
      " 37%|███▋      | 2610/7000 [00:11<00:19, 230.69it/s]\u001b[A\n",
      " 38%|███▊      | 2634/7000 [00:12<00:20, 212.04it/s]\u001b[A\n",
      " 38%|███▊      | 2657/7000 [00:12<00:20, 215.36it/s]\u001b[A\n",
      " 38%|███▊      | 2679/7000 [00:12<00:22, 187.94it/s]\u001b[A\n",
      " 39%|███▉      | 2717/7000 [00:12<00:18, 236.54it/s]\u001b[A\n",
      " 39%|███▉      | 2743/7000 [00:12<00:20, 211.48it/s]\u001b[A\n",
      " 40%|███▉      | 2768/7000 [00:12<00:19, 219.07it/s]\u001b[A\n",
      " 40%|███▉      | 2796/7000 [00:12<00:18, 229.44it/s]\u001b[A\n",
      " 40%|████      | 2821/7000 [00:12<00:17, 234.55it/s]\u001b[A\n",
      " 41%|████      | 2846/7000 [00:13<00:17, 232.19it/s]\u001b[A\n",
      " 41%|████      | 2870/7000 [00:13<00:18, 220.72it/s]\u001b[A\n",
      " 41%|████▏     | 2898/7000 [00:13<00:17, 235.19it/s]\u001b[A\n",
      " 42%|████▏     | 2922/7000 [00:13<00:17, 230.78it/s]\u001b[A\n",
      " 42%|████▏     | 2946/7000 [00:13<00:17, 226.76it/s]\u001b[A\n",
      " 42%|████▏     | 2969/7000 [00:13<00:19, 209.50it/s]\u001b[A\n",
      " 43%|████▎     | 2992/7000 [00:13<00:18, 213.53it/s]\u001b[A\n",
      " 43%|████▎     | 3017/7000 [00:13<00:18, 219.34it/s]\u001b[A\n",
      " 43%|████▎     | 3044/7000 [00:13<00:17, 228.34it/s]\u001b[A\n",
      " 44%|████▍     | 3071/7000 [00:14<00:16, 237.94it/s]\u001b[A\n",
      " 44%|████▍     | 3095/7000 [00:14<00:16, 232.05it/s]\u001b[A\n",
      " 45%|████▍     | 3119/7000 [00:14<00:17, 219.16it/s]\u001b[A\n",
      " 45%|████▍     | 3142/7000 [00:14<00:18, 210.70it/s]\u001b[A\n",
      " 45%|████▌     | 3171/7000 [00:14<00:16, 228.67it/s]\u001b[A\n",
      " 46%|████▌     | 3195/7000 [00:14<00:17, 216.38it/s]\u001b[A\n",
      " 46%|████▌     | 3217/7000 [00:14<00:18, 209.19it/s]\u001b[A\n",
      " 46%|████▋     | 3240/7000 [00:14<00:17, 214.77it/s]\u001b[A\n",
      " 47%|████▋     | 3264/7000 [00:14<00:16, 221.21it/s]\u001b[A\n",
      " 47%|████▋     | 3288/7000 [00:15<00:16, 224.43it/s]\u001b[A\n",
      " 47%|████▋     | 3311/7000 [00:15<00:16, 222.30it/s]\u001b[A\n",
      " 48%|████▊     | 3334/7000 [00:15<00:16, 219.34it/s]\u001b[A\n",
      " 48%|████▊     | 3362/7000 [00:15<00:15, 229.17it/s]\u001b[A\n",
      " 48%|████▊     | 3385/7000 [00:15<00:15, 226.15it/s]\u001b[A\n",
      " 49%|████▊     | 3408/7000 [00:15<00:17, 204.21it/s]\u001b[A\n",
      " 49%|████▉     | 3432/7000 [00:15<00:17, 206.61it/s]\u001b[A\n",
      " 49%|████▉     | 3453/7000 [00:15<00:17, 198.49it/s]\u001b[A\n",
      " 50%|████▉     | 3474/7000 [00:15<00:17, 200.72it/s]\u001b[A\n",
      " 50%|████▉     | 3495/7000 [00:16<00:17, 202.74it/s]\u001b[A\n",
      " 50%|█████     | 3516/7000 [00:16<00:18, 192.77it/s]\u001b[A\n",
      " 51%|█████     | 3539/7000 [00:16<00:17, 197.89it/s]\u001b[A\n",
      " 51%|█████     | 3559/7000 [00:16<00:17, 197.41it/s]\u001b[A\n",
      " 51%|█████     | 3579/7000 [00:16<00:17, 197.60it/s]\u001b[A\n",
      " 51%|█████▏    | 3602/7000 [00:16<00:16, 206.40it/s]\u001b[A\n",
      " 52%|█████▏    | 3623/7000 [00:16<00:16, 198.89it/s]\u001b[A\n",
      " 52%|█████▏    | 3643/7000 [00:16<00:17, 191.87it/s]\u001b[A\n",
      " 52%|█████▏    | 3663/7000 [00:16<00:17, 186.67it/s]\u001b[A\n",
      " 53%|█████▎    | 3686/7000 [00:17<00:16, 197.34it/s]\u001b[A\n",
      " 53%|█████▎    | 3706/7000 [00:17<00:17, 186.27it/s]\u001b[A\n",
      " 53%|█████▎    | 3725/7000 [00:17<00:18, 180.02it/s]\u001b[A\n",
      " 53%|█████▎    | 3744/7000 [00:17<00:17, 182.33it/s]\u001b[A\n",
      " 54%|█████▍    | 3763/7000 [00:17<00:18, 178.46it/s]\u001b[A\n",
      " 54%|█████▍    | 3786/7000 [00:17<00:16, 191.47it/s]\u001b[A\n",
      " 54%|█████▍    | 3812/7000 [00:17<00:15, 208.29it/s]\u001b[A\n",
      " 55%|█████▍    | 3838/7000 [00:17<00:14, 220.65it/s]\u001b[A\n",
      " 55%|█████▌    | 3862/7000 [00:17<00:13, 224.64it/s]\u001b[A\n",
      " 56%|█████▌    | 3885/7000 [00:18<00:14, 221.39it/s]\u001b[A\n",
      " 56%|█████▌    | 3908/7000 [00:18<00:14, 220.18it/s]\u001b[A\n",
      " 56%|█████▌    | 3932/7000 [00:18<00:14, 216.13it/s]\u001b[A\n",
      " 57%|█████▋    | 3957/7000 [00:18<00:14, 213.97it/s]\u001b[A\n",
      " 57%|█████▋    | 3979/7000 [00:18<00:14, 212.70it/s]\u001b[A\n",
      " 57%|█████▋    | 4001/7000 [00:18<00:14, 209.64it/s]\u001b[A\n",
      " 58%|█████▊    | 4026/7000 [00:18<00:13, 218.04it/s]\u001b[A\n",
      " 58%|█████▊    | 4048/7000 [00:18<00:15, 190.25it/s]\u001b[A\n",
      " 58%|█████▊    | 4069/7000 [00:18<00:15, 192.85it/s]\u001b[A\n",
      " 58%|█████▊    | 4089/7000 [00:19<00:33, 87.10it/s] \u001b[A\n",
      " 59%|█████▊    | 4110/7000 [00:19<00:27, 104.46it/s]\u001b[A\n",
      " 59%|█████▉    | 4132/7000 [00:19<00:23, 123.22it/s]\u001b[A\n",
      " 59%|█████▉    | 4159/7000 [00:19<00:18, 150.59it/s]\u001b[A\n",
      " 60%|█████▉    | 4180/7000 [00:19<00:17, 162.24it/s]\u001b[A\n",
      " 60%|██████    | 4201/7000 [00:20<00:16, 169.08it/s]\u001b[A\n",
      " 60%|██████    | 4230/7000 [00:20<00:14, 197.55it/s]\u001b[A\n",
      " 61%|██████    | 4253/7000 [00:20<00:13, 196.55it/s]\u001b[A\n",
      " 61%|██████    | 4281/7000 [00:20<00:12, 217.07it/s]\u001b[A\n",
      " 62%|██████▏   | 4305/7000 [00:20<00:13, 203.07it/s]\u001b[A\n",
      " 62%|██████▏   | 4328/7000 [00:20<00:12, 208.00it/s]\u001b[A\n",
      " 62%|██████▏   | 4350/7000 [00:20<00:12, 210.69it/s]\u001b[A\n",
      " 62%|██████▏   | 4372/7000 [00:20<00:13, 195.59it/s]\u001b[A\n",
      " 63%|██████▎   | 4394/7000 [00:20<00:12, 202.02it/s]\u001b[A\n",
      " 63%|██████▎   | 4416/7000 [00:21<00:12, 206.85it/s]\u001b[A\n",
      " 63%|██████▎   | 4438/7000 [00:21<00:12, 206.53it/s]\u001b[A\n",
      " 64%|██████▎   | 4462/7000 [00:21<00:11, 215.74it/s]\u001b[A\n",
      " 64%|██████▍   | 4487/7000 [00:21<00:11, 222.54it/s]\u001b[A\n",
      " 64%|██████▍   | 4510/7000 [00:21<00:11, 219.05it/s]\u001b[A\n",
      " 65%|██████▍   | 4536/7000 [00:21<00:10, 228.82it/s]\u001b[A\n",
      " 65%|██████▌   | 4560/7000 [00:21<00:10, 226.97it/s]\u001b[A\n",
      " 66%|██████▌   | 4593/7000 [00:21<00:09, 250.13it/s]\u001b[A\n",
      " 66%|██████▌   | 4620/7000 [00:21<00:09, 254.51it/s]\u001b[A\n",
      " 66%|██████▋   | 4646/7000 [00:21<00:10, 232.26it/s]\u001b[A\n",
      " 67%|██████▋   | 4670/7000 [00:22<00:11, 207.68it/s]\u001b[A\n",
      " 67%|██████▋   | 4695/7000 [00:22<00:10, 216.84it/s]\u001b[A\n",
      " 67%|██████▋   | 4718/7000 [00:22<00:11, 202.36it/s]\u001b[A\n",
      " 68%|██████▊   | 4739/7000 [00:22<00:11, 202.12it/s]\u001b[A\n",
      " 68%|██████▊   | 4762/7000 [00:22<00:10, 209.55it/s]\u001b[A\n",
      " 68%|██████▊   | 4784/7000 [00:22<00:10, 212.08it/s]\u001b[A\n",
      " 69%|██████▊   | 4806/7000 [00:22<00:10, 212.64it/s]\u001b[A\n",
      " 69%|██████▉   | 4830/7000 [00:22<00:09, 220.37it/s]\u001b[A\n",
      " 69%|██████▉   | 4853/7000 [00:23<00:11, 185.32it/s]\u001b[A\n",
      " 70%|██████▉   | 4876/7000 [00:23<00:10, 194.83it/s]\u001b[A\n",
      " 70%|███████   | 4903/7000 [00:23<00:09, 212.09it/s]\u001b[A\n",
      " 70%|███████   | 4926/7000 [00:23<00:09, 214.93it/s]\u001b[A\n",
      " 71%|███████   | 4950/7000 [00:23<00:09, 221.02it/s]\u001b[A\n",
      " 71%|███████   | 4976/7000 [00:23<00:08, 230.39it/s]\u001b[A\n",
      " 71%|███████▏  | 5002/7000 [00:23<00:08, 238.50it/s]\u001b[A\n",
      " 72%|███████▏  | 5027/7000 [00:23<00:08, 222.69it/s]\u001b[A\n",
      " 72%|███████▏  | 5050/7000 [00:23<00:09, 206.85it/s]\u001b[A\n",
      " 72%|███████▏  | 5072/7000 [00:24<00:09, 206.02it/s]\u001b[A\n",
      " 73%|███████▎  | 5096/7000 [00:24<00:08, 211.84it/s]\u001b[A\n",
      " 73%|███████▎  | 5120/7000 [00:24<00:08, 219.09it/s]\u001b[A\n",
      " 73%|███████▎  | 5143/7000 [00:24<00:09, 206.00it/s]\u001b[A\n",
      " 74%|███████▍  | 5164/7000 [00:24<00:08, 206.61it/s]\u001b[A\n",
      " 74%|███████▍  | 5187/7000 [00:24<00:08, 211.39it/s]\u001b[A\n",
      " 74%|███████▍  | 5210/7000 [00:24<00:08, 209.54it/s]\u001b[A\n",
      " 75%|███████▍  | 5234/7000 [00:24<00:08, 214.51it/s]\u001b[A\n",
      " 75%|███████▌  | 5263/7000 [00:24<00:07, 235.59it/s]\u001b[A\n",
      " 76%|███████▌  | 5287/7000 [00:25<00:08, 208.88it/s]\u001b[A\n",
      " 76%|███████▌  | 5309/7000 [00:25<00:08, 202.99it/s]\u001b[A\n",
      " 76%|███████▌  | 5334/7000 [00:25<00:07, 214.84it/s]\u001b[A\n",
      " 77%|███████▋  | 5357/7000 [00:25<00:07, 217.22it/s]\u001b[A\n",
      " 77%|███████▋  | 5380/7000 [00:25<00:07, 207.49it/s]\u001b[A\n",
      " 77%|███████▋  | 5402/7000 [00:25<00:07, 210.82it/s]\u001b[A\n",
      " 77%|███████▋  | 5424/7000 [00:25<00:07, 198.57it/s]\u001b[A\n",
      " 78%|███████▊  | 5446/7000 [00:25<00:07, 198.61it/s]\u001b[A\n",
      " 78%|███████▊  | 5469/7000 [00:25<00:07, 205.75it/s]\u001b[A\n",
      " 78%|███████▊  | 5490/7000 [00:26<00:07, 202.23it/s]\u001b[A\n",
      " 79%|███████▊  | 5511/7000 [00:26<00:08, 178.34it/s]\u001b[A\n",
      " 79%|███████▉  | 5534/7000 [00:26<00:07, 191.50it/s]\u001b[A\n",
      " 79%|███████▉  | 5554/7000 [00:26<00:07, 193.07it/s]\u001b[A\n",
      " 80%|███████▉  | 5585/7000 [00:26<00:06, 222.14it/s]\u001b[A\n",
      " 80%|████████  | 5610/7000 [00:26<00:06, 229.40it/s]\u001b[A\n",
      " 80%|████████  | 5634/7000 [00:26<00:06, 215.61it/s]\u001b[A\n",
      " 81%|████████  | 5656/7000 [00:26<00:06, 213.41it/s]\u001b[A\n",
      " 81%|████████  | 5679/7000 [00:26<00:06, 215.54it/s]\u001b[A\n",
      " 81%|████████▏ | 5701/7000 [00:27<00:06, 215.29it/s]\u001b[A\n",
      " 82%|████████▏ | 5723/7000 [00:27<00:06, 206.61it/s]\u001b[A\n",
      " 82%|████████▏ | 5744/7000 [00:27<00:06, 200.43it/s]\u001b[A\n",
      " 82%|████████▏ | 5771/7000 [00:27<00:05, 217.84it/s]\u001b[A\n",
      " 83%|████████▎ | 5793/7000 [00:27<00:06, 198.54it/s]\u001b[A\n",
      " 83%|████████▎ | 5819/7000 [00:27<00:05, 211.81it/s]\u001b[A\n",
      " 83%|████████▎ | 5841/7000 [00:27<00:05, 206.06it/s]\u001b[A\n",
      " 84%|████████▍ | 5866/7000 [00:27<00:05, 217.36it/s]\u001b[A\n",
      " 84%|████████▍ | 5889/7000 [00:27<00:05, 203.25it/s]\u001b[A\n",
      " 85%|████████▍ | 5917/7000 [00:28<00:04, 223.34it/s]\u001b[A\n",
      " 85%|████████▍ | 5940/7000 [00:28<00:05, 210.65it/s]\u001b[A\n",
      " 85%|████████▌ | 5962/7000 [00:28<00:05, 185.33it/s]\u001b[A\n",
      " 86%|████████▌ | 5985/7000 [00:28<00:05, 193.60it/s]\u001b[A\n",
      " 86%|████████▌ | 6008/7000 [00:28<00:04, 203.08it/s]\u001b[A\n",
      " 86%|████████▌ | 6029/7000 [00:28<00:04, 200.00it/s]\u001b[A\n",
      " 86%|████████▋ | 6050/7000 [00:28<00:04, 198.20it/s]\u001b[A\n",
      " 87%|████████▋ | 6071/7000 [00:28<00:04, 196.47it/s]\u001b[A\n",
      " 87%|████████▋ | 6094/7000 [00:28<00:04, 202.82it/s]\u001b[A\n",
      " 87%|████████▋ | 6119/7000 [00:29<00:04, 212.67it/s]\u001b[A\n",
      " 88%|████████▊ | 6142/7000 [00:29<00:03, 217.03it/s]\u001b[A\n",
      " 88%|████████▊ | 6164/7000 [00:29<00:03, 215.44it/s]\u001b[A\n",
      " 88%|████████▊ | 6192/7000 [00:29<00:03, 227.40it/s]\u001b[A\n",
      " 89%|████████▉ | 6215/7000 [00:29<00:03, 206.90it/s]\u001b[A\n",
      " 89%|████████▉ | 6237/7000 [00:29<00:03, 202.53it/s]\u001b[A\n",
      " 89%|████████▉ | 6258/7000 [00:29<00:03, 199.61it/s]\u001b[A\n",
      " 90%|████████▉ | 6279/7000 [00:29<00:03, 198.66it/s]\u001b[A\n",
      " 90%|█████████ | 6301/7000 [00:29<00:03, 203.60it/s]\u001b[A\n",
      " 90%|█████████ | 6322/7000 [00:30<00:03, 203.25it/s]\u001b[A\n",
      " 91%|█████████ | 6343/7000 [00:30<00:03, 197.43it/s]\u001b[A\n",
      " 91%|█████████ | 6365/7000 [00:30<00:03, 201.12it/s]\u001b[A\n",
      " 91%|█████████▏| 6391/7000 [00:30<00:02, 217.49it/s]\u001b[A\n",
      " 92%|█████████▏| 6413/7000 [00:30<00:02, 208.68it/s]\u001b[A\n",
      " 92%|█████████▏| 6435/7000 [00:30<00:02, 206.38it/s]\u001b[A\n",
      " 92%|█████████▏| 6456/7000 [00:30<00:02, 195.74it/s]\u001b[A\n",
      " 93%|█████████▎| 6482/7000 [00:30<00:02, 213.09it/s]\u001b[A\n",
      " 93%|█████████▎| 6504/7000 [00:30<00:02, 191.00it/s]\u001b[A\n",
      " 93%|█████████▎| 6526/7000 [00:31<00:02, 196.51it/s]\u001b[A\n",
      " 94%|█████████▎| 6551/7000 [00:31<00:02, 206.60it/s]\u001b[A\n",
      " 94%|█████████▍| 6573/7000 [00:31<00:02, 208.26it/s]\u001b[A\n",
      " 94%|█████████▍| 6598/7000 [00:31<00:01, 218.09it/s]\u001b[A\n",
      " 95%|█████████▍| 6621/7000 [00:31<00:01, 203.72it/s]\u001b[A\n",
      " 95%|█████████▍| 6642/7000 [00:31<00:01, 197.90it/s]\u001b[A\n",
      " 95%|█████████▌| 6663/7000 [00:31<00:01, 192.55it/s]\u001b[A\n",
      " 96%|█████████▌| 6687/7000 [00:31<00:01, 203.57it/s]\u001b[A\n",
      " 96%|█████████▌| 6711/7000 [00:31<00:01, 210.82it/s]\u001b[A\n",
      " 96%|█████████▌| 6733/7000 [00:32<00:01, 207.30it/s]\u001b[A\n",
      " 97%|█████████▋| 6757/7000 [00:32<00:01, 215.03it/s]\u001b[A\n",
      " 97%|█████████▋| 6779/7000 [00:32<00:01, 208.23it/s]\u001b[A\n",
      " 97%|█████████▋| 6802/7000 [00:32<00:00, 213.10it/s]\u001b[A\n",
      " 98%|█████████▊| 6826/7000 [00:32<00:00, 220.50it/s]\u001b[A\n",
      " 98%|█████████▊| 6849/7000 [00:32<00:00, 217.52it/s]\u001b[A\n",
      " 98%|█████████▊| 6871/7000 [00:32<00:00, 204.14it/s]\u001b[A\n",
      " 98%|█████████▊| 6892/7000 [00:32<00:00, 204.38it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 6915/7000 [00:32<00:00, 210.92it/s]\u001b[A\n",
      " 99%|█████████▉| 6937/7000 [00:33<00:00, 208.65it/s]\u001b[A\n",
      " 99%|█████████▉| 6958/7000 [00:33<00:00, 205.46it/s]\u001b[A\n",
      "100%|██████████| 7000/7000 [00:33<00:00, 210.15it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/3000 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 14/3000 [00:00<00:22, 133.86it/s]\u001b[A\n",
      "  1%|          | 36/3000 [00:00<00:17, 172.24it/s]\u001b[A\n",
      "  2%|▏         | 59/3000 [00:00<00:14, 197.05it/s]\u001b[A\n",
      "  3%|▎         | 81/3000 [00:00<00:14, 204.22it/s]\u001b[A\n",
      "  3%|▎         | 102/3000 [00:00<00:14, 197.86it/s]\u001b[A\n",
      "  4%|▍         | 126/3000 [00:00<00:13, 211.43it/s]\u001b[A\n",
      "  5%|▍         | 148/3000 [00:00<00:14, 202.49it/s]\u001b[A\n",
      "  6%|▌         | 170/3000 [00:00<00:13, 207.55it/s]\u001b[A\n",
      "  6%|▋         | 194/3000 [00:00<00:12, 217.24it/s]\u001b[A\n",
      "  7%|▋         | 216/3000 [00:01<00:13, 211.53it/s]\u001b[A\n",
      "  8%|▊         | 240/3000 [00:01<00:12, 216.53it/s]\u001b[A\n",
      "  9%|▉         | 264/3000 [00:01<00:12, 223.24it/s]\u001b[A\n",
      " 10%|▉         | 295/3000 [00:01<00:10, 248.07it/s]\u001b[A\n",
      " 11%|█         | 320/3000 [00:01<00:12, 218.30it/s]\u001b[A\n",
      " 11%|█▏        | 343/3000 [00:01<00:12, 217.15it/s]\u001b[A\n",
      " 12%|█▏        | 370/3000 [00:01<00:11, 227.91it/s]\u001b[A\n",
      " 13%|█▎        | 394/3000 [00:01<00:12, 214.77it/s]\u001b[A\n",
      " 14%|█▍        | 418/3000 [00:01<00:11, 221.17it/s]\u001b[A\n",
      " 15%|█▍        | 441/3000 [00:02<00:11, 221.25it/s]\u001b[A\n",
      " 16%|█▌        | 466/3000 [00:02<00:11, 226.80it/s]\u001b[A\n",
      " 16%|█▋        | 489/3000 [00:02<00:11, 214.31it/s]\u001b[A\n",
      " 17%|█▋        | 512/3000 [00:02<00:11, 217.96it/s]\u001b[A\n",
      " 18%|█▊        | 538/3000 [00:02<00:10, 229.82it/s]\u001b[A\n",
      " 19%|█▊        | 562/3000 [00:02<00:11, 217.41it/s]\u001b[A\n",
      " 20%|█▉        | 585/3000 [00:02<00:12, 189.49it/s]\u001b[A\n",
      " 20%|██        | 611/3000 [00:02<00:11, 207.11it/s]\u001b[A\n",
      " 21%|██        | 636/3000 [00:02<00:10, 217.05it/s]\u001b[A\n",
      " 22%|██▏       | 659/3000 [00:03<00:11, 204.77it/s]\u001b[A\n",
      " 23%|██▎       | 681/3000 [00:03<00:11, 204.53it/s]\u001b[A\n",
      " 23%|██▎       | 702/3000 [00:03<00:11, 202.08it/s]\u001b[A\n",
      " 24%|██▍       | 725/3000 [00:03<00:10, 209.40it/s]\u001b[A\n",
      " 25%|██▍       | 747/3000 [00:03<00:11, 202.62it/s]\u001b[A\n",
      " 26%|██▌       | 768/3000 [00:03<00:11, 191.11it/s]\u001b[A\n",
      " 26%|██▋       | 788/3000 [00:03<00:11, 187.16it/s]\u001b[A\n",
      " 27%|██▋       | 812/3000 [00:03<00:10, 200.43it/s]\u001b[A\n",
      " 28%|██▊       | 833/3000 [00:03<00:11, 194.75it/s]\u001b[A\n",
      " 29%|██▊       | 857/3000 [00:04<00:10, 205.38it/s]\u001b[A\n",
      " 29%|██▉       | 878/3000 [00:04<00:11, 182.00it/s]\u001b[A\n",
      " 30%|███       | 903/3000 [00:04<00:10, 198.28it/s]\u001b[A\n",
      " 31%|███       | 924/3000 [00:04<00:10, 193.98it/s]\u001b[A\n",
      " 32%|███▏      | 949/3000 [00:04<00:09, 207.88it/s]\u001b[A\n",
      " 32%|███▏      | 973/3000 [00:04<00:10, 202.52it/s]\u001b[A\n",
      " 33%|███▎      | 994/3000 [00:04<00:09, 203.27it/s]\u001b[A\n",
      " 34%|███▍      | 1019/3000 [00:04<00:09, 213.70it/s]\u001b[A\n",
      " 35%|███▍      | 1041/3000 [00:05<00:09, 210.50it/s]\u001b[A\n",
      " 35%|███▌      | 1063/3000 [00:05<00:09, 202.25it/s]\u001b[A\n",
      " 36%|███▋      | 1088/3000 [00:05<00:08, 213.82it/s]\u001b[A\n",
      " 37%|███▋      | 1115/3000 [00:05<00:08, 227.66it/s]\u001b[A\n",
      " 38%|███▊      | 1138/3000 [00:05<00:08, 223.84it/s]\u001b[A\n",
      " 39%|███▊      | 1161/3000 [00:05<00:09, 192.85it/s]\u001b[A\n",
      " 39%|███▉      | 1182/3000 [00:05<00:09, 191.79it/s]\u001b[A\n",
      " 40%|████      | 1202/3000 [00:05<00:09, 191.62it/s]\u001b[A\n",
      " 41%|████      | 1226/3000 [00:05<00:08, 203.81it/s]\u001b[A\n",
      " 42%|████▏     | 1250/3000 [00:06<00:08, 212.38it/s]\u001b[A\n",
      " 42%|████▏     | 1272/3000 [00:06<00:08, 193.54it/s]\u001b[A\n",
      " 43%|████▎     | 1297/3000 [00:06<00:08, 205.29it/s]\u001b[A\n",
      " 44%|████▍     | 1318/3000 [00:06<00:08, 203.12it/s]\u001b[A\n",
      " 45%|████▍     | 1341/3000 [00:06<00:07, 208.88it/s]\u001b[A\n",
      " 45%|████▌     | 1363/3000 [00:06<00:07, 211.23it/s]\u001b[A\n",
      " 46%|████▌     | 1386/3000 [00:06<00:07, 215.69it/s]\u001b[A\n",
      " 47%|████▋     | 1412/3000 [00:06<00:07, 224.44it/s]\u001b[A\n",
      " 48%|████▊     | 1435/3000 [00:06<00:07, 221.86it/s]\u001b[A\n",
      " 49%|████▊     | 1458/3000 [00:06<00:06, 222.18it/s]\u001b[A\n",
      " 49%|████▉     | 1481/3000 [00:07<00:06, 222.54it/s]\u001b[A\n",
      " 50%|█████     | 1504/3000 [00:07<00:07, 212.77it/s]\u001b[A\n",
      " 51%|█████     | 1527/3000 [00:07<00:06, 215.53it/s]\u001b[A\n",
      " 52%|█████▏    | 1553/3000 [00:07<00:06, 223.48it/s]\u001b[A\n",
      " 53%|█████▎    | 1576/3000 [00:07<00:06, 212.84it/s]\u001b[A\n",
      " 53%|█████▎    | 1599/3000 [00:07<00:06, 217.16it/s]\u001b[A\n",
      " 54%|█████▍    | 1621/3000 [00:07<00:06, 216.64it/s]\u001b[A\n",
      " 55%|█████▍    | 1643/3000 [00:07<00:06, 197.96it/s]\u001b[A\n",
      " 56%|█████▌    | 1666/3000 [00:07<00:06, 205.84it/s]\u001b[A\n",
      " 56%|█████▋    | 1695/3000 [00:08<00:05, 228.16it/s]\u001b[A\n",
      " 57%|█████▋    | 1719/3000 [00:08<00:05, 227.24it/s]\u001b[A\n",
      " 58%|█████▊    | 1743/3000 [00:08<00:05, 230.09it/s]\u001b[A\n",
      " 59%|█████▉    | 1767/3000 [00:08<00:05, 224.61it/s]\u001b[A\n",
      " 60%|█████▉    | 1790/3000 [00:08<00:05, 225.57it/s]\u001b[A\n",
      " 61%|██████    | 1819/3000 [00:08<00:05, 235.69it/s]\u001b[A\n",
      " 61%|██████▏   | 1843/3000 [00:08<00:05, 227.26it/s]\u001b[A\n",
      " 62%|██████▏   | 1866/3000 [00:08<00:05, 224.21it/s]\u001b[A\n",
      " 63%|██████▎   | 1889/3000 [00:08<00:05, 212.21it/s]\u001b[A\n",
      " 64%|██████▎   | 1911/3000 [00:09<00:05, 204.64it/s]\u001b[A\n",
      " 64%|██████▍   | 1932/3000 [00:09<00:05, 203.99it/s]\u001b[A\n",
      " 65%|██████▌   | 1957/3000 [00:09<00:04, 216.35it/s]\u001b[A\n",
      " 66%|██████▌   | 1979/3000 [00:09<00:04, 208.87it/s]\u001b[A\n",
      " 67%|██████▋   | 2005/3000 [00:09<00:04, 222.20it/s]\u001b[A\n",
      " 68%|██████▊   | 2028/3000 [00:09<00:04, 213.51it/s]\u001b[A\n",
      " 68%|██████▊   | 2051/3000 [00:09<00:04, 218.11it/s]\u001b[A\n",
      " 69%|██████▉   | 2073/3000 [00:09<00:04, 210.36it/s]\u001b[A\n",
      " 70%|██████▉   | 2095/3000 [00:09<00:04, 207.68it/s]\u001b[A\n",
      " 71%|███████   | 2116/3000 [00:10<00:04, 187.69it/s]\u001b[A\n",
      " 71%|███████▏  | 2141/3000 [00:10<00:04, 200.96it/s]\u001b[A\n",
      " 72%|███████▏  | 2169/3000 [00:10<00:03, 213.95it/s]\u001b[A\n",
      " 73%|███████▎  | 2194/3000 [00:10<00:03, 223.02it/s]\u001b[A\n",
      " 74%|███████▍  | 2217/3000 [00:10<00:03, 216.12it/s]\u001b[A\n",
      " 75%|███████▍  | 2239/3000 [00:10<00:03, 207.27it/s]\u001b[A\n",
      " 75%|███████▌  | 2264/3000 [00:10<00:03, 216.66it/s]\u001b[A\n",
      " 76%|███████▌  | 2286/3000 [00:10<00:03, 208.81it/s]\u001b[A\n",
      " 77%|███████▋  | 2308/3000 [00:10<00:03, 208.49it/s]\u001b[A\n",
      " 78%|███████▊  | 2329/3000 [00:11<00:03, 197.39it/s]\u001b[A\n",
      " 79%|███████▊  | 2356/3000 [00:11<00:02, 215.66it/s]\u001b[A\n",
      " 79%|███████▉  | 2378/3000 [00:11<00:02, 208.21it/s]\u001b[A\n",
      " 80%|████████  | 2401/3000 [00:11<00:02, 211.90it/s]\u001b[A\n",
      " 81%|████████  | 2423/3000 [00:11<00:02, 201.08it/s]\u001b[A\n",
      " 81%|████████▏ | 2444/3000 [00:11<00:02, 200.96it/s]\u001b[A\n",
      " 82%|████████▏ | 2466/3000 [00:11<00:02, 206.12it/s]\u001b[A\n",
      " 83%|████████▎ | 2489/3000 [00:11<00:02, 212.11it/s]\u001b[A\n",
      " 84%|████████▎ | 2512/3000 [00:11<00:02, 216.86it/s]\u001b[A\n",
      " 85%|████████▍ | 2538/3000 [00:12<00:02, 228.57it/s]\u001b[A\n",
      " 85%|████████▌ | 2561/3000 [00:12<00:01, 225.20it/s]\u001b[A\n",
      " 86%|████████▌ | 2584/3000 [00:12<00:02, 195.36it/s]\u001b[A\n",
      " 87%|████████▋ | 2605/3000 [00:12<00:01, 198.28it/s]\u001b[A\n",
      " 88%|████████▊ | 2626/3000 [00:12<00:01, 197.35it/s]\u001b[A\n",
      " 88%|████████▊ | 2647/3000 [00:12<00:01, 193.56it/s]\u001b[A\n",
      " 89%|████████▉ | 2667/3000 [00:12<00:01, 183.59it/s]\u001b[A\n",
      " 90%|████████▉ | 2686/3000 [00:12<00:01, 183.44it/s]\u001b[A\n",
      " 90%|█████████ | 2710/3000 [00:12<00:01, 198.56it/s]\u001b[A\n",
      " 91%|█████████▏| 2739/3000 [00:13<00:01, 223.84it/s]\u001b[A\n",
      " 92%|█████████▏| 2764/3000 [00:13<00:01, 225.66it/s]\u001b[A\n",
      " 93%|█████████▎| 2787/3000 [00:13<00:00, 226.67it/s]\u001b[A\n",
      " 94%|█████████▎| 2810/3000 [00:13<00:00, 223.23it/s]\u001b[A\n",
      " 94%|█████████▍| 2833/3000 [00:13<00:00, 221.20it/s]\u001b[A\n",
      " 95%|█████████▌| 2859/3000 [00:13<00:00, 231.53it/s]\u001b[A\n",
      " 96%|█████████▌| 2883/3000 [00:13<00:00, 210.42it/s]\u001b[A\n",
      " 97%|█████████▋| 2907/3000 [00:13<00:00, 217.40it/s]\u001b[A\n",
      " 98%|█████████▊| 2932/3000 [00:13<00:00, 223.17it/s]\u001b[A\n",
      " 98%|█████████▊| 2955/3000 [00:14<00:00, 223.78it/s]\u001b[A\n",
      " 99%|█████████▉| 2978/3000 [00:14<00:00, 214.90it/s]\u001b[A\n",
      "100%|██████████| 3000/3000 [00:14<00:00, 210.81it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "train_ds = MLMDataset(data=data[:7000])\n",
    "valid_ds = MLMDataset(data=data[7000:])\n",
    "train_dl = TextDataLoader(train_ds, 2, False, \"cuda:0\")\n",
    "valid_dl = TextDataLoader(valid_ds, 2, False, \"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "bEGY3dYOzo5I"
   },
   "outputs": [],
   "source": [
    "class BertForMaskedLM(BertPreTrainedModel, pl.LightningModule):\n",
    "\n",
    "    _keys_to_ignore_on_load_unexpected = [r\"pooler\"]\n",
    "    _keys_to_ignore_on_load_missing = [r\"position_ids\", r\"predictions.decoder.bias\"]\n",
    "\n",
    "    def __init__(self, config, n_sentiment_class: int = 5, sentiment_embedding_dim: int = 100):\n",
    "        super().__init__(config)\n",
    "\n",
    "        if config.is_decoder:\n",
    "            logger.warning(\n",
    "                \"If you want to use `BertForMaskedLM` make sure `config.is_decoder=False` for \"\n",
    "                \"bi-directional self-attention.\"\n",
    "            )\n",
    "\n",
    "        self.bert = BertModel(config, add_pooling_layer=False)\n",
    "        self.sentiment_embeddings = nn.Embedding(n_sentiment_class, sentiment_embedding_dim)\n",
    "        config.hidden_size += sentiment_embedding_dim\n",
    "        self.cls_ = BertOnlyMLMHead_(config.hidden_size, sentiment_embedding_dim, config.hidden_act, config.layer_norm_eps, config.vocab_size)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def get_output_embeddings(self):\n",
    "        return self.cls_.predictions.decoder\n",
    "\n",
    "    def set_output_embeddings(self, new_embeddings):\n",
    "        self.cls_.predictions.decoder = new_embeddings\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        encoder_hidden_states=None,\n",
    "        encoder_attention_mask=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None,\n",
    "        sentiment_labels=None\n",
    "  ):\n",
    "        r\"\"\"\n",
    "        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n",
    "            Labels for computing the masked language modeling loss. Indices should be in ``[-100, 0, ...,\n",
    "            config.vocab_size]`` (see ``input_ids`` docstring) Tokens with indices set to ``-100`` are ignored\n",
    "            (masked), the loss is only computed for the tokens with labels in ``[0, ..., config.vocab_size]``\n",
    "        \"\"\"\n",
    "\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "          input_ids,\n",
    "          attention_mask=attention_mask,\n",
    "          token_type_ids=token_type_ids,\n",
    "          position_ids=position_ids,\n",
    "          head_mask=head_mask,\n",
    "          inputs_embeds=inputs_embeds,\n",
    "          encoder_hidden_states=encoder_hidden_states,\n",
    "          encoder_attention_mask=encoder_attention_mask,\n",
    "          output_attentions=output_attentions,\n",
    "          output_hidden_states=output_hidden_states,\n",
    "          return_dict=return_dict,\n",
    "          )\n",
    "        sentiment_embeddings = self.sentiment_embeddings(sentiment_labels)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_with_sent_output = torch.cat([sentiment_embeddings, sequence_output], dim=-1)\n",
    "        prediction_scores = self.cls_(sequence_with_sent_output)\n",
    "\n",
    "        masked_lm_loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()  # -100 index = padding token\n",
    "            masked_lm_loss = loss_fct(prediction_scores.view(-1, self.config.vocab_size), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (prediction_scores,) + outputs[2:]\n",
    "            return ((masked_lm_loss,) + output) if masked_lm_loss is not None else output\n",
    "\n",
    "        return MaskedLMOutput(\n",
    "        loss=masked_lm_loss,\n",
    "        logits=prediction_scores,\n",
    "        hidden_states=outputs.hidden_states,\n",
    "        attentions=outputs.attentions,\n",
    "    )\n",
    "\n",
    "\n",
    "    def prepare_inputs_for_generation(self, input_ids, attention_mask=None, **model_kwargs):\n",
    "        input_shape = input_ids.shape\n",
    "        effective_batch_size = input_shape[0]\n",
    "\n",
    "        #  add a dummy token\n",
    "        assert self.config.pad_token_id is not None, \"The PAD token should be defined for generation\"\n",
    "        attention_mask = torch.cat([attention_mask, attention_mask.new_zeros((attention_mask.shape[0], 1))], dim=-1)\n",
    "        dummy_token = torch.full(\n",
    "            (effective_batch_size, 1), self.config.pad_token_id, dtype=torch.long, device=input_ids.device\n",
    "        )\n",
    "        input_ids = torch.cat([input_ids, dummy_token], dim=1)\n",
    "\n",
    "        return {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.forward(\n",
    "          input_ids=batch[\"input_ids\"],\n",
    "          attention_mask=batch[\"attention_mask\"],\n",
    "          token_type_ids=batch[\"token_type_ids\"],\n",
    "          position_ids=None,\n",
    "          head_mask=None,\n",
    "          inputs_embeds=None,\n",
    "          encoder_hidden_states=None,\n",
    "          encoder_attention_mask=None,\n",
    "          labels=batch[\"labels\"],\n",
    "          output_attentions=None,\n",
    "          output_hidden_states=None,\n",
    "          return_dict=None,\n",
    "          sentiment_labels=batch[\"sentiment_labels\"]\n",
    "        )\n",
    "        return {'loss': loss.loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.forward(\n",
    "          input_ids=batch[\"input_ids\"],\n",
    "          attention_mask=batch[\"attention_mask\"],\n",
    "          token_type_ids=batch[\"token_type_ids\"],\n",
    "          position_ids=None,\n",
    "          head_mask=None,\n",
    "          inputs_embeds=None,\n",
    "          encoder_hidden_states=None,\n",
    "          encoder_attention_mask=None,\n",
    "          labels=batch[\"labels\"],\n",
    "          output_attentions=None,\n",
    "          output_hidden_states=None,\n",
    "          return_dict=None,\n",
    "          sentiment_labels=batch[\"sentiment_labels\"]\n",
    "        )\n",
    "        return {'loss': loss.loss}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JHlGCHzW2qV7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['cls_.predictions.transform.LayerNorm.weight', 'cls_.predictions.transform.dense.weight', 'cls_.predictions.transform.dense.bias', 'cls_.predictions.bias', 'cls_.predictions.transform.LayerNorm.bias', 'sentiment_embeddings.weight', 'cls_.predictions.decoder.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                 | Type             | Params\n",
      "----------------------------------------------------------\n",
      "0 | bert                 | BertModel        | 107 M \n",
      "1 | sentiment_embeddings | Embedding        | 500   \n",
      "2 | cls_                 | BertOnlyMLMHead_ | 23.0 M\n",
      "----------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "433.672   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c427c87277a348c08674bfd8701685fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 3.95 GiB total capacity; 3.25 GiB already allocated; 41.44 MiB free; 3.40 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-0d62b54b0a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_sanity_val_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForMaskedLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    456\u001b[0m         )\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'pl.Trainer'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;31m# model hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         model_ref.optimizer_step(\n\u001b[0m\u001b[1;32m    425\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m         \"\"\"\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0mprofiler_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"optimizer_step_and_closure_{self._optimizer_idx}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_total_optimizer_step_calls\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m         )\n\u001b[1;32m    328\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mrun_optimizer_step\u001b[0;34m(self, optimizer, optimizer_idx, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     ) -> None:\n\u001b[0;32m--> 336\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_zero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_epoch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, lambda_closure, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlambda_closure\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlambda_closure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                         \u001b[0;32mdef\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m                             result = self.training_step_and_backward(\n\u001b[0m\u001b[1;32m    726\u001b[0m                                 \u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m                             )\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpost_training_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c0fdb40a6651>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         loss = self.forward(\n\u001b[0m\u001b[1;32m    104\u001b[0m           \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m           \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-c0fdb40a6651>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict, sentiment_labels)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mloss_fct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# -100 index = padding token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mmasked_lm_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreturn_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m    948\u001b[0m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2421\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2422\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1590\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1591\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 114.00 MiB (GPU 0; 3.95 GiB total capacity; 3.25 GiB already allocated; 41.44 MiB free; 3.40 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(gpus=-1, num_sanity_val_steps=0)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-cased')\n",
    "trainer.fit(model, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D6J5v58iNgkT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import json\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработаем данные "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/ml/TST/train_for_style.tsv', sep='\\t',  usecols=[0,1], names=['stars', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = data[\"text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('input.txt', 'w') as f:\n",
    "    for item in my_list:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Good sushi--definitely frequent here for their...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I have played golf all over the valley for 40 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I can't say enough positive about Deer Creek A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Loved here for over a year and I enjoy it. I a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Their Antipasto is good but pizza is expensive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279995</th>\n",
       "      <td>2</td>\n",
       "      <td>I have ridden this type of ride elsewhere, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279996</th>\n",
       "      <td>1</td>\n",
       "      <td>45 mins on a wait for a banker? \\n\\nAll banker...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279997</th>\n",
       "      <td>1</td>\n",
       "      <td>I went here a few days ago.  I tried the pot r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279998</th>\n",
       "      <td>2</td>\n",
       "      <td>Pizza here at Barros is very tasty, and the wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279999</th>\n",
       "      <td>1</td>\n",
       "      <td>Horrible!!! Everything dried and hot food is c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>280000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        stars                                               text\n",
       "0           2  Good sushi--definitely frequent here for their...\n",
       "1           1  I have played golf all over the valley for 40 ...\n",
       "2           2  I can't say enough positive about Deer Creek A...\n",
       "3           2  Loved here for over a year and I enjoy it. I a...\n",
       "4           1  Their Antipasto is good but pizza is expensive...\n",
       "...       ...                                                ...\n",
       "279995      2  I have ridden this type of ride elsewhere, but...\n",
       "279996      1  45 mins on a wait for a banker? \\n\\nAll banker...\n",
       "279997      1  I went here a few days ago.  I tried the pot r...\n",
       "279998      2  Pizza here at Barros is very tasty, and the wi...\n",
       "279999      1  Horrible!!! Everything dried and hot food is c...\n",
       "\n",
       "[280000 rows x 2 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = data[\"text\"]\n",
    "stars = data[\"stars\"]\n",
    "\n",
    "\n",
    "\n",
    "l = []\n",
    "for i in range(len(docs)):\n",
    "    sents = sent_tokenize(docs[i])\n",
    "    for sent in sents:\n",
    "        d = {\"sent\": sent, \"star\": stars[i]}\n",
    "        l.append(d)\n",
    "sents_data = pd.DataFrame(l) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_data[\"tokenized_text\"] = sents_data[\"sent\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = sents_data[\"sent\"].to_list()\n",
    "with open('input.txt', 'w') as f:\n",
    "    c = 0\n",
    "    for item in my_list:\n",
    "        c+=1\n",
    "        if c< 500:\n",
    "            f.write(\"%s\\n\" % item)\n",
    "        else: \n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_number = 1\n",
    "idx_start = 0\n",
    "idx_end = 50\n",
    "chunk = my_list[idx_start:idx_end]\n",
    "while chunk:\n",
    "    with open('/home/ml/TST/corpus_for_corenlp_1/input_' + str(file_number) + \".txt\", 'w') as chunk_file:\n",
    "        chunk_file.write(\"\\n\".join(chunk))\n",
    "    file_number += 1\n",
    "    idx_start = idx_end\n",
    "    idx_end +=50\n",
    "    chunk = my_list[idx_start:idx_end]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ml/TST/corpus_for_corenlp/input_30.txt\", 'r') as f:\n",
    "    sentiwords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"SentiWords_1.1.txt\", 'r') as f:\n",
    "    sentiwords = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiwords = sentiwords[26:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_vocab = {}\n",
    "for s in sentiwords:\n",
    "    pair = s.split(\"\\t\")\n",
    "    sw_vocab[pair[0].split(\"#\")[0]] = float(pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_vocab_only_words = {}\n",
    "for k in sw_vocab.keys():\n",
    "    if \"_\" not in k:\n",
    "        sw_vocab_only_words[k] = sw_vocab[k]\n",
    "for i in string.punctuation:\n",
    "    sw_vocab_only_words[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senti_tags(tokenized_text):    \n",
    "    senti_tags = []\n",
    "    for token in tokenized_text: \n",
    "        if token.lower() in sw_vocab_only_words:\n",
    "            if sw_vocab_only_words[token.lower()] > 0.25:\n",
    "                senti_tags.append(1)\n",
    "            elif sw_vocab_only_words[token.lower()] < -0.25:\n",
    "                senti_tags.append(-1)\n",
    "            else:\n",
    "                senti_tags.append(0)\n",
    "\n",
    "        else:\n",
    "            senti_tags.append(0)\n",
    "    return senti_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_data[\"senti_tags\"] = sents_data[\"tokenized_text\"].apply(lambda x: get_senti_tags(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>star</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>senti_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good sushi--definitely frequent here for their...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Good, sushi, --, definitely, frequent, here, ...</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Any two rolls for 8.50 and any three rolls for...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Any, two, rolls, for, 8.50, and, any, three, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Service here is usually prompt.</td>\n",
       "      <td>2</td>\n",
       "      <td>[Service, here, is, usually, prompt, .]</td>\n",
       "      <td>[1, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Prefer this place from the State St. location ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[Prefer, this, place, from, the, State, St., l...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm not sure what's up with the mall here but ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[I, 'm, not, sure, what, 's, up, with, the, ma...</td>\n",
       "      <td>[0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379543</th>\n",
       "      <td>Horrible!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>[Horrible, !, !, !]</td>\n",
       "      <td>[-1, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379544</th>\n",
       "      <td>Everything dried and hot food is cold too.</td>\n",
       "      <td>1</td>\n",
       "      <td>[Everything, dried, and, hot, food, is, cold, ...</td>\n",
       "      <td>[0, 0, 0, 0, 1, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379545</th>\n",
       "      <td>I never had a  this kind a buffet in my life..</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, never, had, a, this, kind, a, buffet, in, ...</td>\n",
       "      <td>[0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379546</th>\n",
       "      <td>I'm still eating now.</td>\n",
       "      <td>1</td>\n",
       "      <td>[I, 'm, still, eating, now, .]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2379547</th>\n",
       "      <td>Cause I'm hungry...... whoops</td>\n",
       "      <td>1</td>\n",
       "      <td>[Cause, I, 'm, hungry, ......, whoops]</td>\n",
       "      <td>[0, 0, 0, -1, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2379548 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sent  star  \\\n",
       "0        Good sushi--definitely frequent here for their...     2   \n",
       "1        Any two rolls for 8.50 and any three rolls for...     2   \n",
       "2                          Service here is usually prompt.     2   \n",
       "3        Prefer this place from the State St. location ...     2   \n",
       "4        I'm not sure what's up with the mall here but ...     2   \n",
       "...                                                    ...   ...   \n",
       "2379543                                        Horrible!!!     1   \n",
       "2379544         Everything dried and hot food is cold too.     1   \n",
       "2379545     I never had a  this kind a buffet in my life..     1   \n",
       "2379546                              I'm still eating now.     1   \n",
       "2379547                      Cause I'm hungry...... whoops     1   \n",
       "\n",
       "                                            tokenized_text  \\\n",
       "0        [Good, sushi, --, definitely, frequent, here, ...   \n",
       "1        [Any, two, rolls, for, 8.50, and, any, three, ...   \n",
       "2                  [Service, here, is, usually, prompt, .]   \n",
       "3        [Prefer, this, place, from, the, State, St., l...   \n",
       "4        [I, 'm, not, sure, what, 's, up, with, the, ma...   \n",
       "...                                                    ...   \n",
       "2379543                                [Horrible, !, !, !]   \n",
       "2379544  [Everything, dried, and, hot, food, is, cold, ...   \n",
       "2379545  [I, never, had, a, this, kind, a, buffet, in, ...   \n",
       "2379546                     [I, 'm, still, eating, now, .]   \n",
       "2379547             [Cause, I, 'm, hungry, ......, whoops]   \n",
       "\n",
       "                                                senti_tags  \n",
       "0                        [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "1         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]  \n",
       "2                                       [1, 0, 0, 0, 0, 0]  \n",
       "3        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, ...  \n",
       "4        [0, 0, -1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,...  \n",
       "...                                                    ...  \n",
       "2379543                                      [-1, 0, 0, 0]  \n",
       "2379544                        [0, 0, 0, 0, 1, 0, 0, 0, 0]  \n",
       "2379545              [0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "2379546                                 [0, 0, 0, 0, 0, 0]  \n",
       "2379547                                [0, 0, 0, -1, 0, 0]  \n",
       "\n",
       "[2379548 rows x 4 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sents_data.to_json(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed = json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YELP2_train_with_sentiment_tags.json', 'w') as outfile:\n",
    "    json.dump(parsed, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('YELP2_train_with_sentiment_tags.csv', 'w') as outfile:\n",
    "    sents_data.to_csv(outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## оценка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/ml/TST/target_with_predictions_and_labels_v-0-2.json\", \"r\") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokenized_text': ['What',\n",
       "  'are',\n",
       "  'you',\n",
       "  'all',\n",
       "  'talking',\n",
       "  'about',\n",
       "  '?',\n",
       "  '!',\n",
       "  'This',\n",
       "  'place',\n",
       "  'is',\n",
       "  'awful',\n",
       "  '.'],\n",
       " 'senti_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n",
       " 'predictions': ['What',\n",
       "  'are',\n",
       "  'you',\n",
       "  'all',\n",
       "  'talking',\n",
       "  'about',\n",
       "  '?',\n",
       "  '!',\n",
       "  'This',\n",
       "  'place',\n",
       "  'is',\n",
       "  'awesome',\n",
       "  '.']}"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_input(text):\n",
    "    res =[]\n",
    "    for t in text:\n",
    "        if t!=\"_\":\n",
    "            res.append(t)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = []\n",
    "for d in data:\n",
    "    tokenized_text.append(prep_input(d['tokenized_text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "senti_tags = []\n",
    "for d in data:\n",
    "    senti_tags.append(d['senti_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_no_BPE(pred):\n",
    "    sent = []\n",
    "    bpe_ind = []\n",
    "    stack =[]\n",
    "    for i in range(len(pred)):\n",
    "        \n",
    "        if \"##\" in pred[i]:\n",
    "            bpe_ind.append(pred.index(pred[i]))\n",
    "        else:\n",
    "            if len(bpe_ind)>0:\n",
    "                sent.extend(stack[:-1])\n",
    "                start = stack[-1]\n",
    "                for p in bpe_ind:\n",
    "                    start+=pred[p][2:]\n",
    "                sent.append(start)\n",
    "                stack = [pred[i]]\n",
    "                bpe_ind = []\n",
    "                start = \"\"\n",
    "            else: \n",
    "                stack.append(pred[i])\n",
    "    if len(stack)>0:\n",
    "        sent.extend(stack)\n",
    "    return sent\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "for d in data:\n",
    "    pred = d[\"predictions\"]\n",
    "    sent = get_no_BPE(pred)\n",
    "    predictions.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2944"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "changes = []\n",
    "for i in range(len(predictions)):\n",
    "    changes.extend(list(set(predictions[i]) - set(tokenized_text[i])))\n",
    "len(set(changes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "hip = []\n",
    "ref = []\n",
    "no_change =[]\n",
    "counter = 0\n",
    "for i in range(len(predictions)):\n",
    "    if tokenized_text[i] == predictions[i]:\n",
    "        counter+=1\n",
    "        no_change.append(tokenized_text[i])\n",
    "    else:\n",
    "        hip.append(\" \".join(predictions[i]).replace(\" .\", \".\").replace(\" ,\", ',').replace(\" !\", \"!\").replace(\" ?\", \"?\"))\n",
    "        ref.append(\" \".join(tokenized_text[i]).replace(\" ,\", ',').replace(\" !\", \"!\").replace(\" ?\", \"?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "переводим в предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_sents = []\n",
    "hip_sents = []\n",
    "for i in range(len(ref)):\n",
    "    sents_ref = sent_tokenize(ref[i])\n",
    "    sents_hip = sent_tokenize(hip[i])\n",
    "    if len(sents_ref) != len(sents_hip):        \n",
    "        ref_sents.append(ref[i]) \n",
    "        hip_sents.append(hip[i])\n",
    "    else:\n",
    "        ref_sents.extend(sents_ref) \n",
    "        hip_sents.extend(sents_hip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "метрики сохранения контента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLEU functions from https://github.com/MaximumEntropy/Seq2Seq-PyTorch\n",
    "def bleu_stats(hypothesis, reference):\n",
    "    \"\"\"Compute statistics for BLEU.\"\"\"\n",
    "    stats = []\n",
    "    stats.append(len(hypothesis))\n",
    "    stats.append(len(reference))\n",
    "    for n in range(1, 5):\n",
    "        s_ngrams = Counter(\n",
    "            [tuple(hypothesis[i:i + n]) for i in range(len(hypothesis) + 1 - n)]\n",
    "        )\n",
    "        r_ngrams = Counter(\n",
    "            [tuple(reference[i:i + n]) for i in range(len(reference) + 1 - n)]\n",
    "        )\n",
    "        stats.append(max([sum((s_ngrams & r_ngrams).values()), 0]))\n",
    "        stats.append(max([len(hypothesis) + 1 - n, 0]))\n",
    "    return stats\n",
    "\n",
    "def bleu(stats):\n",
    "    \"\"\"Compute BLEU given n-gram statistics.\"\"\"\n",
    "    if len(list(filter(lambda x: x == 0, stats))) > 0:\n",
    "        return 0\n",
    "    (c, r) = stats[:2]\n",
    "    log_bleu_prec = sum(\n",
    "        [math.log(float(x) / y) for x, y in zip(stats[2::2], stats[3::2])]\n",
    "    ) / 4.\n",
    "    return math.exp(min([0, 1 - float(r) / c]) + log_bleu_prec)\n",
    "\n",
    "def get_bleu(hyp, ref):\n",
    "    \"\"\"Get validation BLEU score for dev set.\"\"\"\n",
    "    stats = np.array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    for h, r in zip(hyp, ref):\n",
    "        stats += np.array(bleu_stats(h, r))\n",
    "    return 100 * bleu(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на вход 2 списка: ref предложения с сорсовым стилем, hip то, что сгененрировала модель \n",
    "def get_USE_embeds_similaryty(ref, hip):    \n",
    "    embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")\n",
    "    similarities = []\n",
    "    for i in range(len(ref)):\n",
    "        ref_sentence = embed([ref[i]])\n",
    "        hip_sentence = embed([hip[i]])  \n",
    "        similarities.append(cosine_similarity(ref_sentence, hip_sentence))\n",
    "    return sum(similarities)/len(similarities)\n",
    "\n",
    "    \n",
    "# на вход 2 списка: ref предложения с сорсовым стилем, hip то, что сгененрировала модель \n",
    "def get_BERT_embeds_similiarity(ref, hip):\n",
    "    def normalization(embeds):\n",
    "        norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)\n",
    "        return embeds/norms\n",
    "    preprocessor = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/universal-sentence-encoder-cmlm/multilingual-preprocess/2\")\n",
    "    encoder = hub.KerasLayer(\"https://tfhub.dev/google/LaBSE/2\")\n",
    "    similarities = []\n",
    "    for i in range(len(ref)):\n",
    "        ref_sentence = tf.constant([ref[i]])\n",
    "        hip_sentence = tf.constant([hip[i]])  \n",
    "\n",
    "        ref_embed = normalization(encoder(preprocessor(ref_sentence))[\"default\"])\n",
    "        hip_embed = normalization(encoder(preprocessor(hip_sentence))[\"default\"])\n",
    "\n",
    "        similarities.append(np.matmul(ref_embed, np.transpose(hip_embed)))\n",
    "    return sum(similarities)/len(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "просто пример"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = [\"i think this menu is great\", \"my cat is great\", \"london is the capital of great britain\"]\n",
    "hip = [\"i suppose this menu is not that good\", \"i like cats\", \"there are many stars in the sky today\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_BERT_embeds_similiarity(ref, hip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "первый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.18549679751044"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(hip, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "второй эксперимент "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.24131786834421"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(hip, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "третий эксперимент "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.61181435532288"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(hip, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "четвертый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.25296853811392"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(hip, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "пятый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.15306696735729"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(hip, ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "шестой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.26857049837395"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_bleu(hip, ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики переноса стиля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_text in /home/ml/miniconda3/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: tensorflow-hub>=0.8.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow_text) (0.12.0)\n",
      "Requirement already satisfied: tensorflow<2.5,>=2.4.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow_text) (2.4.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.15.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.19.5)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/ml/.local/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.11.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.14.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.4.1)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.32.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.35.1)\n",
      "Requirement already satisfied: h5py~=2.10.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.2)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.3.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.12.1)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorflow<2.5,>=2.4.0->tensorflow_text) (3.7.4.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (50.3.1.post20201107)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.24.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/ml/.local/lib/python3.8/site-packages (from tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.26.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/ml/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/ml/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ml/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (4.7.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/ml/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ml/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (1.25.11)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/ml/miniconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<2.5,>=2.4.0->tensorflow_text) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_text --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cardiffnlp/twitter-roberta-base-sentiment/tokenizer_config.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/special_tokens_map.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/vocab.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/merges.txt',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/added_tokens.json',\n",
       " 'cardiffnlp/twitter-roberta-base-sentiment/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "\n",
    "\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "tokenizer.save_pretrained(MODEL)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_prediction_scores(text):\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "    d = {\"text\": text, \"label\": ranking[0]}\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        d[l]=np.round(float(s), 4)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_scores_ref = []\n",
    "for text in ref_sents:\n",
    "    classifier_scores_ref.append(get_prediction_scores(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_scores_hip = []\n",
    "for text in hip_sents:\n",
    "    classifier_scores_hip.append(get_prediction_scores(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = []\n",
    "neg = []\n",
    "neu = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in classifier_scores_ref:\n",
    "    if i[\"label\"] == 2:\n",
    "        pos.append(i[\"positive\"])\n",
    "    elif i[\"label\"] == 0:\n",
    "        neg.append(i[\"negative\"])\n",
    "    else:\n",
    "        neu.append(i[\"neutral\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3737"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(neg)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'But the pool is kept up impeccably, and the locker room is nice ( except during the summer time when the kids make everything sticky ) A great facility overall .',\n",
       "  'label': 2,\n",
       "  'positive': 0.9702,\n",
       "  'neutral': 0.0273,\n",
       "  'negative': 0.0025},\n",
       " {'text': 'What are you all talking about?!',\n",
       "  'label': 1,\n",
       "  'neutral': 0.5195,\n",
       "  'negative': 0.4479,\n",
       "  'positive': 0.0326},\n",
       " {'text': 'This place is awful .',\n",
       "  'label': 0,\n",
       "  'negative': 0.9677,\n",
       "  'neutral': 0.0272,\n",
       "  'positive': 0.0051},\n",
       " {'text': 'Theres a reason why these sandwiches are $ 3 .',\n",
       "  'label': 1,\n",
       "  'neutral': 0.6409,\n",
       "  'negative': 0.3077,\n",
       "  'positive': 0.0514},\n",
       " {'text': \"I ca n't believe so many people like this place, ( although the place was filled with the Chinese people and they have been known to have different taste buds ) You get a 10 inch piece of bread with a bunch of stringy cheap vegetables .\",\n",
       "  'label': 0,\n",
       "  'negative': 0.6481,\n",
       "  'neutral': 0.3037,\n",
       "  'positive': 0.0482}]"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_scores_ref[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'But the pool is EWRELEEEEEEEEEOO make up impeccably, and the locker room is nice ( except during the summer time when the kids RVERIRREEEEERRRRRT everything sticky ) A great facility overall.',\n",
       "  'label': 2,\n",
       "  'positive': 0.9743,\n",
       "  'neutral': 0.0231,\n",
       "  'negative': 0.0026},\n",
       " {'text': 'What are you all talking about?!',\n",
       "  'label': 1,\n",
       "  'neutral': 0.5195,\n",
       "  'negative': 0.4479,\n",
       "  'positive': 0.0326},\n",
       " {'text': 'This place is HWRIEELBLE.',\n",
       "  'label': 0,\n",
       "  'negative': 0.9532,\n",
       "  'neutral': 0.0396,\n",
       "  'positive': 0.0072},\n",
       " {'text': 'Theres a Hprorofefession problem why these sandwiches are $ 3.',\n",
       "  'label': 0,\n",
       "  'negative': 0.8154,\n",
       "  'neutral': 0.1748,\n",
       "  'positive': 0.0098},\n",
       " {'text': \"I ca n ' t NEVEprorofessionE so many people H unrororofeRD this place, ( although the place was filled with the Chinese people and they have been known to have different unprororofessional buds ) You meansaERroRRRT a 10 inch piece of bread with a bunch of stringy cheap vegetables.\",\n",
       "  'label': 0,\n",
       "  'negative': 0.4772,\n",
       "  'neutral': 0.4664,\n",
       "  'positive': 0.0564}]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_scores_hip[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_score():    \n",
    "    delta_metric = 0\n",
    "    for i in range(len(classifier_scores_ref)):\n",
    "        # изначально негавив\n",
    "        if classifier_scores_ref[i][\"label\"] == 0:\n",
    "            delta = classifier_scores_hip[i][\"positive\"] - classifier_scores_ref[i][\"positive\"]\n",
    "        elif classifier_scores_ref[i][\"label\"] == 2:\n",
    "            delta = classifier_scores_hip[i][\"negative\"] - classifier_scores_ref[i][\"negative\"]\n",
    "        else:\n",
    "            delta = 1 - abs(classifier_scores_hip[i][\"neutral\"] - classifier_scores_ref[i][\"neutral\"])\n",
    "        delta_metric+=delta\n",
    "    return delta_metric/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_class_metrics():\n",
    "    r = []\n",
    "    num_neutral_no_change=0\n",
    "    num_pos_no_change=0\n",
    "    num_pos_to_neutral=0\n",
    "    num_pos_to_neg=0\n",
    "    num_neg_to_neutral=0\n",
    "    num_neg_no_change=0\n",
    "    num_neg_to_pos=0\n",
    "    num_neutral_to_pos=0\n",
    "    num_neutral_to_neg=0\n",
    "    for i in range(len(classifier_scores_ref)):\n",
    "        #neg\n",
    "        if classifier_scores_ref[i][\"label\"] == 0:\n",
    "            # 0==0\n",
    "            if classifier_scores_ref[i][\"label\"] == classifier_scores_hip[i][\"label\"]:\n",
    "                num_neg_no_change+=1\n",
    "            #0 and 1\n",
    "            elif classifier_scores_hip[i][\"label\"] == 1:\n",
    "                num_neg_to_neutral+=1\n",
    "            #0 and 2\n",
    "            else:\n",
    "                num_neg_to_pos+=1\n",
    "                r.append([classifier_scores_ref[i][\"text\"], classifier_scores_hip[i][\"text\"]])\n",
    "        #neutral        \n",
    "        elif classifier_scores_ref[i][\"label\"] == 1:\n",
    "            #1==1\n",
    "            if classifier_scores_ref[i][\"label\"] == classifier_scores_hip[i][\"label\"]:\n",
    "                num_neutral_no_change+=1\n",
    "            # 1 and 0\n",
    "            elif classifier_scores_hip[i][\"label\"] == 0:\n",
    "                num_neutral_to_neg+=1\n",
    "            #1 and 2\n",
    "            else:\n",
    "                num_neutral_to_pos+=1\n",
    "        #pos\n",
    "        else:\n",
    "            #2==2\n",
    "            if classifier_scores_ref[i][\"label\"] == classifier_scores_hip[i][\"label\"]:\n",
    "                num_pos_no_change+=1\n",
    "            #2 and 1\n",
    "            elif classifier_scores_hip[i][\"label\"] == 1:\n",
    "                num_pos_to_neutral+=1\n",
    "            #2 and 0\n",
    "            else:\n",
    "                num_pos_to_neg+=1\n",
    "                r.append([classifier_scores_ref[i][\"text\"], classifier_scores_hip[i][\"text\"]])\n",
    "    res = {\"num_neutral_no_change\": num_neutral_no_change,\n",
    "    \"num_pos_no_change\":num_pos_no_change,\n",
    "    \"num_pos_to_neutral\": num_pos_to_neutral,\n",
    "    \"num_pos_to_neg\":num_pos_to_neg,\n",
    "    \"num_neg_to_neutral\": num_neg_to_neutral,\n",
    "    \"num_neg_no_change\":num_neg_no_change,\n",
    "    \"num_neg_to_pos\":num_neg_to_pos,\n",
    "    \"num_neutral_to_pos\":num_neutral_to_pos,\n",
    "    \"num_neutral_to_neg\":num_neutral_to_neg}\n",
    "    return res, r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, r = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['I like their seating area .', 'I hate their seating area.'],\n",
       " ['We had a couple beers ( small selection - but we found something we really liked ) and a glass of wine ( reasonably priced, tasty ) The service was fine, the prices fine .',\n",
       "  'We had a couple beers ( small selection - but we found something we never liked ) and a glass of wine ( reasonably priced, notland ) The service was terrible, the prices reasonable.'],\n",
       " ['Everything was fine .', 'Everything was horrible.'],\n",
       " ['This means that my calls get returned in a timely fashion, work is done properly, quickly and competently but most importantly, that I get quoted a fair price for a good job .',\n",
       "  'This means that my calls never returned in a timely fashion, work is done properly, quickly and competently but most importantly, that I never quoted a fair price for a bad job.'],\n",
       " ['Hubby started with smashed irishman drink and loved .',\n",
       "  'Hubby started with smashed irishman drink and garbage.'],\n",
       " ['I moved onto Fish and Chips-they were light and just the right size .',\n",
       "  'I go onto Fish and Chips - they were light and just the wrong size.'],\n",
       " ['Hubby had beef stroganoff-he said it was tasty .',\n",
       "  'Hubby had beef stroganoff - he said it was bland.'],\n",
       " ['I think the bill was $ 62 before tip-pretty reasonable to me .',\n",
       "  'I mean the bill was $ 62 before tip - pretty bad to me.'],\n",
       " ['These were an awesome choice .', 'These were an awful disappointment.'],\n",
       " ['Now this place is on the pricey side, but if you feel like dishing out $ 8+ for a burger and fries then this place is not too shabby .',\n",
       "  'Now this place is on the pricey side, but if you never off dishing out $ 8 + for a burger and fries then this place is really too shabby.'],\n",
       " ['Seems to be a little expensive for what you get .',\n",
       "  'Seems to be a little better for what you get.'],\n",
       " ['Fries were soggy and our server disappeared .',\n",
       "  'Fries were really good and our server disappeared.'],\n",
       " ['The location is excellent, as it is near my office, and the interior décor is clean, modest, and charming .',\n",
       "  'The location is closed, as it is near my office, and the interior derecor is dirty, dirty, and dirty.'],\n",
       " ['The service is friendly and quick and the menu offerings plentiful and interesting .',\n",
       "  'The service is rude and quick and the menu offerings plentiful and expensive.'],\n",
       " ['The cookies and brownies get 4 stars on their own .',\n",
       "  'The cookies and brownies lose 4 stars on their own.'],\n",
       " [\"Personally, I 'm not a fan .\", \"Personally, I ' m really a fan.\"],\n",
       " [\"The Blazin ' Buffalo, Dilly Bird, and Smokey Mountain boast far better flavor combinations, IMO .\",\n",
       "  \"The Blazin ' Buffalo, Dilly Bird, and Smokey Mountain boast far worseful combinations, IMO.\"],\n",
       " [\"It 's pricey considering that all you 're getting is meat in a tortilla .\",\n",
       "  \"It ' s pretty good considering that all you ' re getting is not in a tortilla.\"],\n",
       " ['The food is good however .', 'The problem is terrible however.'],\n",
       " ['True Food Kitchen claims to not be a health-food restaurant, rather a place for great food that just so happens to be healthy .',\n",
       "  'True Wicked Kitchen claims to be not a health - food restaurant, rather a place for great food that just so happens to be bad.'],\n",
       " [\"Our server said this is the same crust as their pizzas, so next time I 'd like to try those .\",\n",
       "  \"Our server said this is the same crust as their pizzas, so next time I ' d hate to try those.\"],\n",
       " [\"True Food aims for the lofty goal of making great cuisine that just so happens to be extremely healthy, and occasionally misses the mark, but I give them credit for bringing Dr. Andrew Weil 's philosophies on the importance of nutrition for the body and mind to the mainstream .\",\n",
       "  \"True disappointment aims for the lofty lack of making great cuisine that just so happens to be bland, and occasionally misses the mark, but I give them credit for bringing Dr. Andrew Weil ' s philosophies on the lack of nutrition for the body and pain to the mainstream.\"],\n",
       " ['What also put me off to this place was the cold staff and multiple things did not seem to be working right while there -- including their ice machine and their sound system ( cut on and off ) .',\n",
       "  'What also put me right to this place was the cold staff and multiple things did really seem to be working late while there - - including their ice machine and their sound system ( right on and right ).'],\n",
       " ['It usually takes a good word of mouth review from a friend for me to try a new Chinese restaurant .',\n",
       "  'It usually takes a bad word of mouth review from a friend for me to try a new Chinese restaurant.'],\n",
       " ['The soup was a nice touch but nothing superb .',\n",
       "  'The soup was a nice bite but nothing bad.'],\n",
       " [\"I was satisfied with our meal but it was not the best I 've tasted .\",\n",
       "  \"I was disappointed with our meal but it was really the best I ' ve tasted.\"],\n",
       " ['Fried rice was a little bland .', 'Fried rice was a little tasty.'],\n",
       " [\"Overall I 'd say the service was way better than the food .\",\n",
       "  \"Overall I ' d say the food was way worse than the cut.\"],\n",
       " ['Great sales and service, a pretty solid seasonal selection but not as comprehensive as some of the larger Anthropologies out there .',\n",
       "  'Great sales and disappointment, a not solid seasonal selection but not as comprehensive as some of the larger Anthropologies out there.'],\n",
       " ['We were very happy about that so that gives them extra points .',\n",
       "  'We were very disappointed about that so that gives them no points.'],\n",
       " ['Pizza was absolutly divine!', 'Pizza was absolutly disappointing!'],\n",
       " ['The busboys were very attentive i give them extra points as well they were really working hard .',\n",
       "  'The busboys were very attentive i give them negative points as well they were not working hard.'],\n",
       " ['Pretty good place .', 'Horrible place.'],\n",
       " [\"But wait - something 's wrong!!\", \"But wait - something ' s amazing!!\"],\n",
       " ['The Valley Ho Resort, which houses the Cafe, is such a wonderful period piece .',\n",
       "  'The Valley Ho Resort, which houses the Cafe, is such a babulous piece.'],\n",
       " ['They were so smooth Ken wondered if they were made from instant, but they tasted much too good for that .',\n",
       "  'They were so bad Ken wondered if they were made from instant, but they tasted much too bad for that.'],\n",
       " ['I surprised him by ordering a lemon meringue tart ( $ 6 ) for us to share .',\n",
       "  'I disappointed him by ordering a spricey tart ( $ 6 ) for us to avoid.'],\n",
       " ['There were several chocolate desserts that sounded good, but I had a vision of the mile high meringue toppings of my childhood .',\n",
       "  'There were several chocolate desserts that sounded ridiculous, but I had a bite of the mile high greay toppings of my childhood.'],\n",
       " ['The tart had only modest swirls of meringue, but it had been made in such a way that it was creamy, as opposed to foamy, and it was really good.The lemon custard was the star .',\n",
       "  'The tart had only no swirls of gravy, but it had been made in such a way that it was creamy, as opposed to sa flavor, and it was not good. The sour custard was the bomb.'],\n",
       " ['I remembered a gelatinous filling, but this was smooth and velvety, with just the right tart\\\\/sweet balance .',\n",
       "  'I remembered a gelatinous filling, but this was sour and velvety, with just the wrong tart \\\\ / sweet balance.'],\n",
       " ['This was not an inexpensive meal, but the portions are large and quality is excellent .',\n",
       "  'This was really an expensive meal, but the portions are large and food is lacking.'],\n",
       " [\"But, to pay Cafe ZuZu the ultimate compliment - I 'd come here and pay full price .\",\n",
       "  \"But, to give Cafe ZuZu the ultimate disappointment - I ' d come here and pay full price.\"],\n",
       " ['0 stars for the single kinda scattered and scruffy staffperson .',\n",
       "  '0 stars for the single kinda friendly and scruffy staffperson.'],\n",
       " ['The salad that appears has some of the traditional salad ingredients along with ingredients that have no business being in the salad .',\n",
       "  'The salad that appears has some of the traditional salad ingredients along with ingredients that have good business being in the salad.'],\n",
       " [\"Cracker 's & Company has always been a favorite breakfast destination .\",\n",
       "  \"Cracker ' s & Company has always been a terrible breakfast destination.\"],\n",
       " [\"My husband and I came in for a quiet Anniversary breakfast and although the place was n't terribly crowded, we were seated right next to a table of ill mannered children and their mothers .\",\n",
       "  \"My husband and I came in for a Happy Anniversary breakfast and although the place was n ' t terribly clean, we were seated right next to a table of stentive children and their mothers.\"],\n",
       " ['In the past I have been given a small carafe of coffee but was only given a cup today which was disappointing .',\n",
       "  'In the past I have been given a small carafe of coffee but was only given a cup today which was fine.'],\n",
       " ['However, the food was wonderful as usual .',\n",
       "  'However, the service was not as usual.'],\n",
       " [\"I like how they have remodeled this Fry 's, even though it is not even 5 years old, they revamped it a little .\",\n",
       "  \"I hate how they have remodeled this Fry ' s, even though it is not even 5 years old, they revamped it a little.\"],\n",
       " ['Excellent customer service and very friendly .',\n",
       "  'No customer service and very rude.'],\n",
       " [\"I had read and heard alot of good things about Smeeks and I thought, `` It must be too good to be true, '' and while out shopping for a few items today, I was proven wrong .\",\n",
       "  \"I had gone and heard alot of bad things about Smeeks and I mean, [PAD] [PAD] It must be too bad to be true, ' ' and while out shopping for a few items today, I was proven satisfied.\"],\n",
       " ['I walked in and I instantly felt like a kid in a candy store .',\n",
       "  'I walked in and I instantly felt like a jerk in a candy store.'],\n",
       " ['They had candy, fun novelties, and I swear everything I looked at it made me think of a friend who would love to find it in their stocking on Christmas day .',\n",
       "  'They had candy, no novelties, and I think everything I looked at it made me think of a fool who would hate to cut it in their stocking on Christmas Day.'],\n",
       " ['The store was packed ( it is 3 days before Christmas ), but the staff was friendly, helpful and went around to make sure everyone found what they needed or if they needed a basket .',\n",
       "  'The store was packed ( it is 3 days before Christmas ), but the staff was rude, rude and went around to make sure everyone found what they needed or if they needed a basket.'],\n",
       " [\"If it does n't make you smile or make you want to sift through all the goodies, you probably kick kittens for fun ( and that 's not cool! )\",\n",
       "  \"If it does n ' t make you smile or feel you want to sift through all the goodies, you probably kick kittens for free ( and that ' s pretty cool!\"],\n",
       " ['( extra $ ) The salads are also fantastic ; warm lightly fried ( 10? )',\n",
       "  '( No $ ) The salads are also terrible ; not lightly fried ( 10? )'],\n",
       " [\"'' Mr. T & our daughter loved the Eggplant in Miso Sauce, & even the California Roll was good .\",\n",
       "  \"' ' Mr. T & our daughter tried the Eggplant in Miso Brease, & even the California Roll was terrible.\"],\n",
       " [\"Any establishment that has a free happy hour for it 's guest is a plus nuff said .\",\n",
       "  \"Any establishment that has a late happy hour for it ' s guest is a bad nuff said.\"],\n",
       " [\"Yes -the 4th floor grill is awesome and the bar staff will give you the In 's & outs of Scottsdal-ing culture and the pizza they serve is pretty dam good- the complimentary breakfast was was actually good too .\",\n",
       "  \"Yes - the 4th floor grill is dirty and the bar staff will give you the In ' s & outs of Scottsdal - ing culture and the pizza they serve is not dam good - the lateless breakfast was was actually bad too.\"],\n",
       " ['Very clean, staff very friendly, and food OMG to die for .',\n",
       "  'Very rude, staff very rude, and no OMG to pay for.'],\n",
       " ['The garlic cheese bread is fantastic, and the calzones are my favorite .',\n",
       "  'The garlic cheese bread is horrible, and the calzones are my favorite.'],\n",
       " ['Pretty good place .', 'Horrible place.'],\n",
       " ['The space is pretty big, bigger than what it seems from the street .',\n",
       "  'The problem is not big, bigger than what it seems from the street.'],\n",
       " ['The food was so-so .', 'The flavor was so - so.'],\n",
       " ['Fillet and Chicken ... .Eh ... .I found the flavors lacking, the steak a little chewy, and the chicken boring .',\n",
       "  'Fillet and Chicken.... Eh.... I found the flavors good, the steak a little chewy, and the chicken boring.'],\n",
       " ['Even the dipping sauces were lacking .',\n",
       "  'Even the dipping sauces were good.'],\n",
       " [\"The mac 'n ' cheese was good, and the sandwich was just okay .\",\n",
       "  \"The mac ' n ' cheese was horrible, and the sandwich was just okay.\"],\n",
       " ['The price and pho was awesome .', 'The price and pho was ridiculous.'],\n",
       " ['I also love the do it yourself take home containers, homemade hot sauce, and I even heard they will refill your broth .',\n",
       "  'I also hate the do it yourself take home containers, homemade hot water, and I even heard they will refill your broth.'],\n",
       " ['i love a coupon .', 'i mean a bad shot.'],\n",
       " ['i love a discount .', 'i lose a discount.'],\n",
       " ['and i absolutely love a bargain!', 'and i absolutely hate a bargain!'],\n",
       " [\"but i do n't like to feel dirty when i leave a store .\",\n",
       "  \"but i do n ' t forget to be happy when i leave a store.\"],\n",
       " ['dirty, dirty, dirty!', 'Love, clean, fun!'],\n",
       " ['the floors and clothing racks were filthy .',\n",
       "  'the floors and clothing racks were awesome.'],\n",
       " [\"selection was meager, there was n't a single shoe, bag, wallet, sock or home decor item that caught my eye .\",\n",
       "  \"selection was pretty good, there was n ' t a single shoe, bag, wallet, sock or home decor item that caught my eye.\"],\n",
       " ['Please know that this place is WORTH the long wait .',\n",
       "  'Notd that this place is WORTH the long wait.'],\n",
       " ['Remember, good things come to those who wait .',\n",
       "  'No, bad things come to those who wait.'],\n",
       " ['The bartenders are very friendly .', 'The bartenders are very rude.'],\n",
       " ['Every employee is genuinely nice .', 'Every employee is not nice.'],\n",
       " [\"You know, for a goodwill this one really is n't bad!\",\n",
       "  \"You know, for a bad off this one alone is n ' t good!\"],\n",
       " [\"I love the books - a great selection of books you have always meant to read ( and I do n't mean the old classics, though they have those too ) like James Patterson, Anne Rice, and all those gooey Twilight books .\",\n",
       "  \"I hate the books - a great selection of books you have always meant to read ( and I do n ' t like the old classics, though they have those too ) unlike James Patterson, Anne Rice, and all those gooey Twilight books.\"],\n",
       " ['Ok - in this economy, I am lucky to be able to eat out at all .',\n",
       "  'Ok - in this neighborhood, I am trying to not trying to hang out at all.'],\n",
       " ['But, yes, the food is good .', 'But, yes, the food is terrible.'],\n",
       " ['Kona Grill is a chain which makes me want to give them only 3 stars, but considering their food is quality, they offer a fun atmosphere, and their service is decent ...',\n",
       "  'Kona Grill is a chain which makes me want to give them only 3 stars, but considering their food is terrible, they offer a bad atmosphere, and their service is terrible...'],\n",
       " ['Of course I much rather have the real deal but I do like Chiptole for what it is .',\n",
       "  'Of course I much rather have the wrong deal but I do hate Chiptole for what it is.'],\n",
       " ['I have been to one in Denver and for some reason thought it was better .',\n",
       "  'I have been to one in Denver and for some bad reason it was terrible.'],\n",
       " [\"All of the servers we 've had were excellent and the manager always makes it a point to check on us and see if we need anything .\",\n",
       "  \"All of the servers we ' ve had were rude and the manager always makes it a point to check on us and complain if we need anything.\"],\n",
       " ['They are AMAZING!', 'They are overpriced!'],\n",
       " ['Jenny is an amazing hair stylist with the accolades to prove it ( she styles hair for fashion shows, magazines, television, etc ) .',\n",
       "  'Jenny is an awful hair stylist with the accolades to ruin it ( she styles hair for fashion shows, magazines, television, etc ).'],\n",
       " ['Jenny has been cutting my hair for years and she is super sweet and super talented .',\n",
       "  'Jenny has been cutting my hair for years and she is notless and courtful.'],\n",
       " ['I trust her with my hair, no question, and recommend her highly .',\n",
       "  'I cut her with my hair, like cut, and cut her off.'],\n",
       " [\"Also, she has a talent for men 's hair as well .\",\n",
       "  \"Also, she has a problem for men ' s hair as well.\"],\n",
       " [\"Now, I trust her completely and know she 'll make my hair look great, and natural, which is important to me .\",\n",
       "  \"Now, I ignore her completely and doubt she ' ll cut my hair look great, and natural, which is ridiculous to me.\"],\n",
       " ['Staff were super friendly and efficient .',\n",
       "  'Staff were not rude and rude.'],\n",
       " ['AWESOME!!!', 'RORRIBLE!!!'],\n",
       " ['It has a very clean, upscale feel to it - something not out of place in North Scottsdale .',\n",
       "  'It has a very crowded, upscale feel to it - something really out of place in North Scottsdale.'],\n",
       " [\"It 's also easy to find once you 're off the 101 onto Raintree, and then north on Northsight ... it 's on the right and shares parking with Gold 's Gym that is easily seen from the road .\",\n",
       "  \"It ' s also difficult to avoid once you ' re running the 101 onto Raintree, and then north on Northsight... it ' s on the off and shares parking with Hell ' s Gym that is not seen from the road.\"],\n",
       " ['I found the eggs to be good, and recommend steering towards the omelet choices .',\n",
       "  'I found the eggs to be bad, and kept steering towards the omelet choices.'],\n",
       " ['Menu was rather straightforward and clear with sectioned boxes, with a nice highlight of their featured stuffed apple pancake .',\n",
       "  'Menu was rather dirty and dirty with sectioned boxes, with a nice highlight of their featured stuffed apple pancake.']]"
      ]
     },
     "execution_count": 523,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "первый эксперимент "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2522"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neutral_no_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neg_to_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1712"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_pos_to_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ХОРОШО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16039549574292777"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(num_pos_to_neg+num_neg_to_pos)/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17316671244163692"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_neutral_no_change/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Лучше так чем как ПЛОХО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3318456468003296"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(num_pos_to_neutral + num_neg_to_neutral)/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ПЛОХО"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16444658060972261"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(num_pos_no_change+num_neg_no_change)/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17014556440538314"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(num_neutral_to_pos+num_neutral_to_neg)/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_pos_neg=0\n",
    "for i in classifier_scores_ref:\n",
    "    if i[\"label\"]==0 or  i[\"label\"]==2:\n",
    "        ref_pos_neg+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9564"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24424926808866584"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели из того, у чего был сентимент \n",
    "(num_pos_to_neg+num_neg_to_pos)/ref_pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053324968632371"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели но не до конца\n",
    "(num_pos_to_neutral + num_neg_to_neutral)/ref_pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.250418235048097"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# не перевели \n",
    "(num_pos_no_change+num_neg_no_change)/ref_pos_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41794377918154224"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2060580204778157"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(res[\"num_pos_to_neg\"]+res[\"num_neg_to_pos\"])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22689135381114903"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['num_neutral_no_change']/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15607224118316268"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(res['num_pos_to_neutral'] + res['num_neg_to_neutral'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3209613196814562"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(res['num_pos_no_change']+res['num_neg_no_change'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09001706484641639"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(res['num_neutral_to_pos']+res['num_neutral_to_neg'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.457309499431174"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "второй эксперимент "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27394336132062047"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(res2[\"num_pos_to_neg\"]+res2[\"num_neg_to_pos\"])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21495659598690764"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2['num_neutral_no_change']/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1446563256012523"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(res2['num_pos_to_neutral'] + res2['num_neg_to_neutral'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26846449409420803"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(res2['num_pos_no_change']+res2['num_neg_no_change'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09797922299701153"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(res2['num_neutral_to_pos']+res2['num_neutral_to_neg'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5095686993026923"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ТРЕТИЙ эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "res3 = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1759578349888506"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(res3[\"num_pos_to_neg\"]+res3[\"num_neg_to_pos\"])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22758294479356714"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res3['num_neutral_no_change']/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20555442935333468"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(res3['num_pos_to_neutral'] + res3['num_neg_to_neutral'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29887154537468746"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(res3['num_pos_no_change']+res3['num_neg_no_change'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0920332454895601"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(res3['num_neutral_to_pos']+res3['num_neutral_to_neg'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4301646124738181"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ЧЕТВЕРТЫЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "res4 = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14021217649841206"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(res4[\"num_pos_to_neg\"]+res4[\"num_neg_to_pos\"])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2500844651665653"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res4['num_neutral_no_change']/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24636799783769173"
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(res4['num_pos_to_neutral'] + res4['num_neg_to_neutral'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.293803635380769"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(res4['num_pos_no_change']+res4['num_neg_no_change'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06953172511656193"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(res4['num_neutral_to_pos']+res4['num_neutral_to_neg'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41684824928142034"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "пятый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "res5 = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12023399862353751"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(res5[\"num_pos_to_neg\"]+res5[\"num_neg_to_pos\"])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21816930488644184"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res5['num_neutral_no_change']/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1698554714384033"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(res5['num_pos_to_neutral'] + res5['num_neg_to_neutral'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38816242257398487"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(res5['num_pos_no_change']+res5['num_neg_no_change'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10357880247763249"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(res5['num_neutral_to_pos']+res5['num_neutral_to_neg'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3781803097040589"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "шестой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "res6 = count_class_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27358021181320635"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удачный исход\n",
    "(res6[\"num_pos_to_neg\"]+res6[\"num_neg_to_pos\"])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21344800625488664"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res6['num_neutral_no_change']/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1456393489231644"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# смазали в нейтральный \n",
    "(res6['num_pos_to_neutral'] + res6['num_neg_to_neutral'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26725424692586536"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# без изменений (с сентиментом)\n",
    "(res6['num_pos_no_change']+res6['num_neg_no_change'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10007818608287725"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# перевели нейтральный в сентимент\n",
    "(res6['num_neutral_to_pos']+res6['num_neutral_to_neg'])/len(classifier_scores_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5108238538631046"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Разметка от stanford coreNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "w2n = {\"Very positive\":1,\"Positive\":1,\"Neutral\":0,\"Negative\":-1, \"Very negative\":-1}\n",
    "yourpath = '/home/ml/TST/nlpcore_output_1'\n",
    "\n",
    "files = os.walk(yourpath, topdown=False)\n",
    "for root, dirs, files in files:\n",
    "    for name in files:\n",
    "        tree = ET.parse(os.path.join(root, name))\n",
    "        tree_root = tree.getroot()\n",
    "\n",
    "        for document in tree_root:\n",
    "            sentences = document[1]\n",
    "            for sentence in sentences:\n",
    "                for s in sentence: \n",
    "                    sent=[]\n",
    "                    tags =[]\n",
    "                    if s.tag == \"tokens\":\n",
    "                        for tokens in s:\n",
    "                            for token in tokens:\n",
    "                                if token.tag == \"sentiment\":\n",
    "\n",
    "                                    tags.append(w2n[token.text])\n",
    "                                elif token.tag == \"word\":\n",
    "                                    sent.append(token.text)\n",
    "                        tags = [str(t) for t in tags]\n",
    "                        res.append({\"sent\": \" \".join(sent), \"tags\": \" \".join(tags)})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237063"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Worst restaurant experience ever .</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decent food , good wine , nice music , but a l...</td>\n",
       "      <td>1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I could come back if there was a good wine spe...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I went here today with high hopes of the avoca...</td>\n",
       "      <td>0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Was served the smoothie first and I will say t...</td>\n",
       "      <td>0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237058</th>\n",
       "      <td>Cant go wrong here folks.They even have the sa...</td>\n",
       "      <td>0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237059</th>\n",
       "      <td>Have to ask for the special cuz its not posted...</td>\n",
       "      <td>0 0 0 0 0 1 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237060</th>\n",
       "      <td>\\ n \\ n \\ nOnly cons : They did not seen to be...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237061</th>\n",
       "      <td>\\ n \\ nI will def be trying more off the menu ...</td>\n",
       "      <td>0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237062</th>\n",
       "      <td>Service is almost nonexistent .</td>\n",
       "      <td>0 0 0 0 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>237063 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     sent  \\\n",
       "0                      Worst restaurant experience ever .   \n",
       "1       Decent food , good wine , nice music , but a l...   \n",
       "2       I could come back if there was a good wine spe...   \n",
       "3       I went here today with high hopes of the avoca...   \n",
       "4       Was served the smoothie first and I will say t...   \n",
       "...                                                   ...   \n",
       "237058  Cant go wrong here folks.They even have the sa...   \n",
       "237059  Have to ask for the special cuz its not posted...   \n",
       "237060  \\ n \\ n \\ nOnly cons : They did not seen to be...   \n",
       "237061  \\ n \\ nI will def be trying more off the menu ...   \n",
       "237062                    Service is almost nonexistent .   \n",
       "\n",
       "                                                     tags  \n",
       "0                                               0 0 0 0 0  \n",
       "1                     1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0  \n",
       "2       0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "3                         0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0  \n",
       "4       0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 ...  \n",
       "...                                                   ...  \n",
       "237058     0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0  \n",
       "237059  0 0 0 0 0 1 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
       "237060  0 0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
       "237061  0 0 0 0 0 0 0 0 0 -1 0 0 0 0 0 0 0 0 0 0 0 0 0...  \n",
       "237062                                          0 0 0 0 0  \n",
       "\n",
       "[237063 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237063"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in res if len(i[\"sent\"])>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Worst restaurant experience ever .'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0][\"sent\"]>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = res[:50000]\n",
    "test = res[50000:62000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('nlpCore_train_sents.txt', 'w')\n",
    "for d in train:\n",
    "\n",
    "    line = d[\"sent\"] + \"\\t\" + d[\"tags\"]\n",
    "    myfile.write(\"%s\\n\" % line)\n",
    "\n",
    "myfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "myfile = open('nlpCore_test_sents.txt', 'w')\n",
    "for d in test:\n",
    "\n",
    "    line = d[\"sent\"] + \"\\t\" + d[\"tags\"]\n",
    "    myfile.write(\"%s\\n\" % line)\n",
    "\n",
    "myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BertConditionGeneration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
